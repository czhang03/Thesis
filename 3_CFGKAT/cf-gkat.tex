
% continuations
\newcommand{\conti}[1]{\mathbf{#1}}
\newcommand{\acc}[1]{{\conti{acc} ~ #1}}  % accept with an output indicator value
\newcommand{\ret}{{\conti{ret}}}  % return, terminate the program
\newcommand{\brk}[1]{\conti{brk} ~ #1}  % break with an output indicator value
\newcommand{\jmp}[1]{{\conti{jmp} ~ #1}} % goto a label

% paper specific
\newcommand{\contWith}{\mathbf{cont}}
\newcommand{\exitWith}{\mathbf{exit}}
\newcommand{\iter}{\mathrm{iter}}


\chapter{CF-GKAT, fast control-flow verification}
\label{chapter:Conclusions}
\thispagestyle{myheadings}

% set this to the location of the figures for this chapter. it may
% also want to be ../Figures/2_Body/ or something. make sure that
% it has a trailing directory separator (i.e., '/')!
\graphicspath{{4_Conclusion/Figures/}}

\section{Motivation and Overview}

The usual baseline to reason about correctness of control-flow manipulation is \emph{trace semantics}, which can be represented by guarded languages. 
Intuitively, trace semantics abstracts the meaning of the primitive tests and actions that occur in a program, and instead focus on how tests determine which actions are performed, and in what order.

\emph{Guarded Kleene Algebra with Tests}~\cite{kozen_BohmJacopiniTheorem_2008a,Schmid_Kappé_Kozen_Silva_2021},
provides a nice (co)algebraic framework to reason about trace semantics.
For example, GKAT is able to verify nontrivial  program equivalences like
\[
 \{\ \comWhile{b}{p}\ \};\ \comWhile{s}{\{\ q;\ \comWhile{b}{p}\ \}} ≡
 \comWhile{b ∨ c}{\{\ \comITE{b}{p}{q}\ \}}
\]
Furthermore, unlike KAT, GKAT equivalence is decidable in nearly-linear time (assuming the set of primitive tests is fixed)~\cite{Schmid_Kappé_Kozen_Silva_2021}, making GKAT a practical framework to reason about trace semantics of simple \command{while}-programs.

Nevertheless, GKAT still lacks important constructs that are ubiquitous among control-flow transformation algorithms.
First, as mentioned, GKAT disregards the meaning of primitive programs and tests.
For instance, when given a program like
\begin{equation}
 \comITE{y \neq 0}{\{\ x := 42;\ p\ \}}{\{\ x := 42;\ q\ \}}%
 \label[prog]{prog: assignment inside branches}
\end{equation}
we can note that a change in the value of $x$ does not have effect on whether or not $y \neq 0$.
Hence, it should be possible to factor the assignment to $x$ out of the branches, and obtain
\begin{equation}
 x := 42;\ \comITE{y \neq 0}{p}{q}%
 \label[prog]{prog: assignment outside branches}
\end{equation}
Unfortunately, GKAT does not admit this equivalence, precisely because it is agnostic with respect to the meaning of primitive actions.
However, moving to a setting that accounts for the semantics of actions is hard, because Turing completeness — and by extension, undecidability — lurks nearby.
In fact, just considering commutativities of non-interfering statements, like 
\[(x := x + 1); (y := y + 1) = (y := y + 1); (x := x + 1), \]
the theory can be quickly become undecidable~\cite{Kozen_1996, kuznetsov_ComplexityReasoningKleene_2023, azevedodeamorim_KleeneAlgebraCommutativity_2024}.

Second, GKAT excludes non-local control-flow structures like \(\command{goto}\), \(\comBrk\), and \(\comRet\).
In a general imperative language, lacking these commands will not limit its expressivity -- indeed, these control structures can be recovered using variables~\cite{erosa-hendren-1994}.

However, lacking both variables and non-local control structures, GKAT is not able to express all control flows of real-world programs.
As a very concrete example, consider the programs below.
\Cref{prog: goto version two state automaton} has a control flow strategy based purely on labels and $\texttt{goto}$.
Meanwhile, \Cref{prog: break version two state automaton} is structured as a loop with the option to terminate early using $\comBrk$.
These programs happen to be trace equivalent (i.e., they always execute the same actions in the same order) but represent behavior not expressible in plain GKAT~\cite{kozen_BohmJacopiniTheorem_2008a,schmid_GuardedKleeneAlgebra_2021}.
\begin{align}
  & \begin{aligned}
      & \comLabel{ℓ₀};\ \comIT{\neg b}{\comGoto{ℓ₁}};\ p;\ \comIT{b}{\comGoto{ℓ₁}};\ q;\ \comGoto{ℓ₀};\ \comLabel{ℓ₁}
    \end{aligned}\label[prog]{prog: goto version two state automaton}
 \\[3pt]
  & \comWhile{b}{\{\ p;\ \comITE{¬ b}{q}{\comBrk}\ \}}
 \label[prog]{prog: break version two state automaton}
\end{align}

As it turns out, deciding equivalence between these complex programs is essential in verifying control-flow manipulation procedures.
Specifically, consider the control flow structuring phase of a decompiler~\cite{cifuentes-1994}, which is tasked with converting conditional and unconditional jumps into more conventional control flow constructs as best as possible.
\Cref{prog: goto version two state automaton} can be thought of as pseudo-assembly that models the input of this process, and \Cref{prog: break version two state automaton} is a plausible outcome.
Thus the control-flow structuring process is correct when \Cref{prog: goto version two state automaton,prog: break version two state automaton} are equivalent.

To overcome these limitations of GKAT, we propose control flow GKAT (CF-GKAT), a extension of GKAT that is capable of equating programs making use of non-local control flow and indicator variables.

First, \emph{indicator variables} can be assigned and tested against hardcoded values, and do not appear in other primitive actions and tests.
Thus, assignments like $x := 42$ are allowed, but assignments like $x := y + 1$ are not.
This addition strikes a delicate balance: it is strong enough to verify well-known control-flow transformation algorithms~\cite{yakdan_NoMoreGotos_2015,erosa-hendren-1994}, yet weak enough to still exclude general computation (keeping program equivalence decidable).

Second, we extend GKAT with non-local control-flow constructs, including \(\comGoto{\!}\), \(\comBrk\) and \(\comRet\).
However, the non-local nature of these commands prevents a compositional semantics --- after all, the precise meaning of a statement like \(\comBrk\) depends on its context.
To overcome these challenges, we propose a intermediate semantics, named \emph{continuation semantics}, which appends a continuation to every trace (\Cref{sec:continuation-semantics}). 
Specifically, at the end of the trace, the program can either accept (terminate normally), break, return, or go to a label.
Then, the trace semantics of the program can be obtained by resolving these continuations.

%FIXME: CZ: This paragraph is still bit out of place to me
Inspired by the triangular correspondence between deterministic trace semantics, GKAT, and GKAT automaton, we were able to design an automaton model for CF-GKAT, where every CF-GKAT expression can be unfolded into an CF-GKAT automaton through Thompson's construction (\Cref{tab: thompson's construction}), while preserving the continuation semantic (\Cref{the:thompson-correctness}). 
Furthermore, CF-GKAT automata and continuation semantics can be lowered into GKAT automata and trace semantics respectively, while preserving their semantic correspondence (\Cref{the:cf-gkat-automaton-lowering-correctness}). 
With the Thompson's construction and the lowering, we are able to reduce the problem of deciding trace equivalence of programs into deciding the bisimulation of two GKAT automata, which is known to be efficient~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}. 

\smallskip
As a result of these extensions, CF-GKAT is able to soundly and completely verify trace equivalence of a larger class of programs, while preserving the nearly-linear efficiency of GKAT.
For instance, it can automatically check that \Cref{prog: break version two state automaton,prog: goto version two state automaton} are equivalent to each other, and also to \Cref{prog: indicator version two state automaton} (below), which is their single-loop equivalent obtained via the Böhm-Jacopini theorem~\cite{DBLP:journals/cacm/BohmJ66}.
\begin{align}
 \begin{aligned}
   & x := 1;\ \comWhile{x \neq 0}{\{ \\
   & \qquad \comITE{x = 1 ∧ b}{\{\ p;\ x := 2\ \} \\
   & \qquad\qquad}{\comITE{x = 2 ∧ ¬ b} {\{\ q;\ x := 1\ \} \\
   & \qquad\qquad}{x := 0} }\ \}}                                 \\
 \end{aligned} \label[prog]{prog: indicator version two state automaton}
\end{align}

To put this theory to work, we implemented an proof-of-concept equivalence checker for CF-GKAT\@.
This checker is able to validate highly non-trivial program transformations, such as the aforementioned Böhm-Jacopini conversion~\cite{DBLP:journals/cacm/BohmJ66}.


\section{CF-GKAT Expression and Semantics}
%FIXME: CZ: multiple indicator variable?

In this section, we introduce the language of CF-GKAT, and gradually develop its semantics.
We begin by explaining the syntax of CF-GKAT;\@ after that, we delve into the semantics of its tests.
We then introduce the model of \emph{(labeled and indexed families of) guarded languages with continuations}, which is flattened into to a model based on \emph{guarded languages}.
Having defined these tools, we then conclude by giving a semantics to CF-GKAT programs in this model.
Along the way, we will single out and explain some of the finer points using examples.

% We fix a single indicator variable $x$, as well as a finite set $I$ of possible indicator values.

\subsection{Syntax}

The syntax of CF-GKAT consists of two levels, similar to GKAT\@.
At the bottom level, there are \emph{tests}; these are Boolean assertions that can occur as guards inside conditional statements, or within assertions that occur in the program text.
To model them, we fix a finite set of primitive tests $B$, which represent uninterpreted expressions that may or may not hold.
The full syntax is as follows.
\[
 \BExp_I ∋ e_{b}, f_{b} ::=
 \false ∣ \true ∣ b ∈ B ∣ {\color{blue}x = i\ (i ∈ I)}
 ∣ e_{b} ∨ f_{b} ∣ e_{b} ∧ f_{b} ∣ \overline{e_{b}}
\]
Compared to GKAT and KAT, tests in CF-GKAT include the \emph{indicator variable test} $x = i$ (highlighted in \textcolor{blue}{blue}) for each \emph{indicator value} $i$ drawn from a finite but fixed set of possible indicator values $I$.
As the notation suggests, this test holds when the indicator variable $x$ currently has the value $i$.
% Since the set \(I\) is finite, any complex predicate \(P\) on \(I\) can be encoded as a disjunction that enumerates all the values in \(P\)\ : \[⋁ \{(x = i) ∣ P(i)\}.\]

The top level syntax of GKAT is built using a finite set of uninterpreted commands \(K\) (the \emph{primitive actions}), as well as \emph{assertions} of the form $\comAssert{e_b}$, where $e_b \in \BExp_I$ is a boolean expression.
Expressions are composed using sequencing, \texttt{if} statements, and \texttt{while} loops.
CF-GKAT extends the base elements of the syntax with indicator variable assignments \(x := i\) (for each $i \in I$), which changes the value of the indicator variable \(x\) to \(i\).
In addition, it adds the non-local control flow commands $\comBrk$ and $\comRet$, as well as $\comGoto{\ell}$ and $\comLabel{\ell}$, where $\ell$ is taken from a fixed but finite set of labels $L$.
The full syntax is given below; constructs new compared to GKAT are highlighted in \textcolor{blue}{blue} again.
\begin{align*}
 \CFGKAT ∋ e, f ::= {}&
 \comAssert{e_b}
 ∣ p ∈ K
 ∣ {\color{blue}x := i\ (i ∈ I)}
 ∣ e; f
 ∣ \comITE{e_b}{e}{f} ∣ {} \\
 &
 \comWhile{e_b}{e}
 ∣ {\color{blue} \comBrk}
 ∣ {\color{blue} \comRet}
 ∣ {\color{blue} \comGoto{ℓ}\ (ℓ ∈ L)}
 ∣ {\color{blue} \comLabel{ℓ}\ (ℓ ∈ L)}
\end{align*}

A \emph{valid program}, or \emph{program} for short, is an expression without (1)~duplicate labels, (2)~$\command{goto}$ commands with an undefined label, or (3)~$\comBrk$ statements that occur outside a loop.
For the sake of simplicity, we assume that the reader does not require a more formal definition of this notion.

\begin{example}
 Any GKAT expression is a valid program.
 Also, \cref{prog: break version two state automaton,%
  prog: goto version two state automaton,%
  prog: indicator version two state automaton}
 from the introduction are all valid CF-GKAT expressions.
 The following expressions are \emph{not} valid programs:
 \begin{align*}
  \comLabel{ℓ}; (\comITE{t}{\comLabel{ℓ}; p}{q}) \tag{the label \(ℓ\) is defined twice} \\
  (\comWhile{\true}{p}); \comGoto{ℓ} \tag{the label \(ℓ\) is undefined} \\
  \comITE{t}{\comBrk}{p} \tag{$\comBrk$ appears outside a loop}
 \end{align*}
\end{example}

%FIXME: move to semantics
\begin{remark}
 For soundness, it is important that the indicator variable $x$ does not
 occur in any primitive test $t ∈ T$ or action $p ∈ K$.
 In other words, $x$ is completely divorced from the other actions in the program,
 and may influence execution only by affecting flow control.
\end{remark}

\subsection{Boolean semantics}

To assign a semantics to CF-GKAT expressions, we first need to talk about the semantics of the Boolean sublanguage.
Similar to GKAT~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}, the semantics of a boolean is defined as a set of program states that satisfy the boolean expression. 
The difference however is that we not only need to keep track of which primitive tests are satisfied under the boolean expression (represented by atoms), but also need to record the indicator variables that satisfy the boolean expression.

Thus the semantics of a boolean expression is a set of atom-indicator pairs.
Formally, we can calculate the semantics of a given Boolean expression \(e_b ∈ \BExp_I\) by induction.
\begin{definition}
 We define the \emph{Boolean semantics} function $C(-): \BExp_I → 2^{\At × I}$ inductively,
 as follows.
 \begin{align*}
  C( \false ) & ≜ ∅
    & C( t )& ≜ \{ (α, i) ∣ t ∈ α, i ∈ I \}
    & C( e_{b} ∨ f_{b} ) & ≜ C( e_{b} ) ∪ C( f_{b} ) \\
  C( \true )  & ≜ \At × I
    & C( x = i ) & ≜ \{ (α, i) ∣ α ∈ \At \}
    & C( e_{b} ∧ f_{b} ) & ≜ C( e_{b} ) ∩ C( f_{b} ) \\
  & & & & C( ¬ e_{b} ) & ≜ \At × I \setminus C( e_b )
 \end{align*}
\end{definition}
We will overload the notation \(C\) later for continuation semantics/interpretation, because the boolean semantics is a restriction of the continuation semantics to assertions.

\begin{example}
 Take $B = \{ b_1, b_2 \}$ and $I = \{ 1, 2, 3 \}$; then we can calculate that
 \[
  C( (b_1 ∨ ¬ b_2) ∧ (x = 2) ) = \{
  (b_1 b_2, 2),
  (b_1 \overline{b₂}, 2),
  (\overline{b₁} \overline{b₂}, 2)
  \}
 \]
 In other words, the test above holds in execution contexts where $b₁$ and $b₂$ are both true (first element) or both false (last element), and those where $b₁$ is true but $b₂$ is false (middle element).
 In contrast, $C( x = 1 ∧ x = 3) = ∅$, which is to say that this test does not hold in any execution context, because the indicator variable \(x\) cannot be both 1 and 3 at the same time.
\end{example}

\subsection{Guarded languages with continuations}\label{sec:continuation-semantics}

We can now turn our attention to the semantics of CF-GKAT\@.
Like (G)KAT, the semantics of CF-GKAT is given in terms of \emph{guarded languages}~\cite{Schmid_Kappé_Kozen_Silva_2021,Kozen_1997}, which are best thought of as sets of symbolic traces of the program.
Our semantics of a CF-GKAT expression will ultimately be a guarded language.
To get there, however, we will need continuation semantics, a semantics that can account for the indicator variables as well as the non-local flow control statements.
The remainder of this subsection is dedicated to explaining the domain of this continuation semantics, based on \emph{guarded words with continuations}.
Intuitively, these are guarded words equipped with a piece of information called a \emph{continuation}, which contains relevant information about how flow control continues after the program ends.
This could, for instance, tell us that the execution will continue at a location marked by a label.

The possibility of including continuation information at the end of a trace allows us to define a semantics of CF-GKAT expressions inductively.
This is especially necessary in the case of non-local control flow, because the label may occur in an entirely different part of the program whose traces have not yet been computed.
Once the continuation semantics of a CF-GKAT program is known, we can flatten it into a guarded language.

\begin{definition}
 A \emph{guarded word with continuation} is a pair $w ⋅ c$,
 where $w$ is a guarded word and $c$ is a \emph{continuation},
 which can take on one of the following forms for $i ∈ I$ and $ℓ ∈ L$:
 \begin{mathpar}
  \acc{i} \and
  \brk{i} \and
  \ret \and
  \jmp{(ℓ, i)}
 \end{mathpar}
 We write $C$ for the set of all continuations.
 A set of guarded words with continuations is a \emph{guarded language with continuations}; the set of guarded languages with continuations is written $𝒞$.
\end{definition}
Intuitively, the different types of continuation may be interpreted as follows:
\begin{itemize}
    \item
    The continuation $\acc{i}$ represents that the trace has successfully reached the end of this part of the program, with indicator value \(i\).
    Execution can be picked up if the program is put in a larger context --- e.g., if $w \cdot \acc{i}$ is a trace of $e$, then it may be combined with a trace found when $f$ is executed with indicator value $i$ to compute the semantics of $e; f$.
    \item
    A continuation of the form $\brk{i}$ signals that the trace ends by halting the loop in which it occurs.
    Execution can resume only after this loop (with indicator value $i$).
    This kind of trace cannot be composed on the right, as is done for traces with accepting continuations, because we first need to enclose it in a loop to halt; it will then be converted into $\acc{i}$.
    \item
    The continuation $\ret$ represents a trace that ends in the program halting completely.
    Traces of this kind will percolate upwards in the semantics, without changing their continuation.
    These are intended to model the $\comRet$ statement, which halts the program no matter how deeply it is nested.
    In this case, the indicator value does not matter any more.
    \item
    Finally, the continuation $\jmp{(\ell, i)}$ is put on traces that will continue executing from label $\ell$, with indicator value $i$.
    Like $\brk{i}$ and $\ret$, these traces do not compose on the right, but unlike $\brk{i}$ this continuation does not change, as jump resolution happens only at the end, when the semantics is known for the entire program.
\end{itemize}

\begin{example}
 Let $w$ be the guarded word from the previous example;
 the guarded word with continuation $w ⋅ \jmp{(ℓ₁, 2)}$
 represents a partial program trace that takes the steps represented by $w$,
 and will continue executing at the label $ℓ₁$ with an indicator value of $2$.
\end{example}

%FIXME: change L to G to avoid conflict with sets of labels

\subsection{Indexed families and sequencing}
The continuation semantics of a CF-GKAT expression takes a starting indicator value, and produces a guarded language with continuations representing the traces of that program when started with this indicator value.
This semantics is modeled by the following.
\begin{definition}
An \emph{indexed family} of guarded languages (with continuations), or ``indexed family'' for the sake of brevity, is function from $I$ to guarded languages (with continuations).
Similar to guarded languages, we use \(W, V\) to denote a family of languages.
To lighten notation, we write \(Wᵢ\) to denote \(W(i)\).
\end{definition}

Similar to guarded languages, indexed families can be composed in several ways.
In particular, we are interested in the sequencing operation and the Kleene star operation of indexed families, because these will turn out to be useful when defining the continuation semantics of CF-GKAT\@.

When sequencing two families \(W\) and \(V\), the traces in \(W_i\) with a continuation of the form $\acc{j}$ will be composed with traces in \(V_j\); traces with different continuations are copied over in full, because they do not compose on the right.
Formally, this operation is defined as follows.

\begin{definition}%
\label{def:sequencing}
 Let $W, V: I \to 𝒞$.
 We write $W ⋄ V$ for the \emph{sequencing} (or \emph{concatenation}) operation of \(W\) and \(V\), which is defined as the smallest family of guarded languages with continuations (in the pointwise order) satisfying the following rules for all $i,j ∈ I$ as well as all $ℓ ∈ L$:
 \begin{mathpar}
  \inferrule{%
   wα ⋅ \acc{j} ∈ Wᵢ \\
   αx ⋅ c ∈ Vⱼ
  }{%
   wαx ⋅ c ∈ (W ⋄ V)ᵢ
  }
  \and
  \inferrule{%
   w ⋅ c ∈ Wⱼ \\
   c \in \{ \brk{i}, \acc{i}, \jmp{(\ell, i)} \}
  }{%
   w ⋅ c ∈ (W ⋄ V)ⱼ
  }
 \end{mathpar}
\end{definition}
The first rule composes accepting traces in $W$ with traces in $V$, picking up with the indicator value where the first trace left off.
Note also that this rule requires the last atom in the trace on the left to match the first atom in the trace on the right, because we want the second trace to start from the machine state computed in the first trace.
This mirrors the \emph{coalesced product} used to define the sequential composition of guarded languages (without continuations).
The last rule ensures that traces that encountered non-local control flow within $W$ are preserved in $W ⋄ V$.

\begin{example}%
\label{example:sequencing}
 Let $I = \{1,2\}$, and let $W$ and $V$ be indexed families given by:
 \begin{align*}
  W₁ & = \{ αpβ ⋅ \brk{1},\; βpα ⋅ \acc{2} \}
    & W₂& = \{ αqβ \cdot \acc{1} \} \\
  V₁ & = \{ γqβ ⋅ \ret \}
    & V₂ & = \{ αrβ ⋅ \jmp{(ℓ₁, 1)} \}
  \intertext{
   Then we can compute that the sequencing $W ⋄ V$ is the following indexed family:
  }
  (W ⋄ V)₁ & = \{ αpβ ⋅ \brk{1},\; βpαrβ ⋅ \jmp{(ℓ₁, 1)} \}
           & (W ⋄ V)₂ & = ∅
 \end{align*}
 Here, we find that $(W ⋄ V)_1$ contains $α p β ⋅ \brk{1}$ by the second rule, because $W_1$ does.
 Furthermore, the trace $β p α ⋅ \acc{2}$ in $W_1$ is composed with $α r β ⋅ \jmp{(\ell_1, 1)}$ from $V_2$ to form $β p α r β ⋅ \jmp {(\ell_1, 1)}$ in $(W ⋄ V)_1$, by the first rule.
 The set $(W ⋄ V)_2$ is empty, because despite the fact that $αqβ ⋅ \acc{1} ⋅ \acc{1} ∈ W_2$, there is no trace in $V_2$ that starts with $β$, and so neither rule can apply.
\end{example}

\subsection{continuation semantics, from the start}
With the theory of indexed families in place, we can now define the continuation semantics $C(e)^♯$ of a CF-GKAT program $e$ in terms of an indexed family.
We start with the base cases.

\begin{definition}[continuation semantics, base]
 For all $i, j ∈ I$, we define the following sets:
 \begin{align*}
  C(\comAssert{e_b})ᵢ^♯ & ≜ \{ α ⋅ \acc{i} ∣ (α, i) ∈ C( e_b ) \}
    & C( \comGoto{ℓ} )ᵢ^♯ & ≜ \{ α ⋅ \jmp{(ℓ, i)} ∣ α ∈ \At \} \\
  C(p)ᵢ^♯             & ≜ \{α p β ⋅ \mathbf{acc}\ i ∣ α, β ∈ \At\}
    & C( \comLabel{ℓ} )ᵢ^♯ & ≜ \{ α ⋅ \acc{i} ∣ α ∈ \At \} \\
  C( x := j )ᵢ^♯ & ≜ \{ α ⋅ \acc{j} ∣ α ∈ \At \}
    & C( \comBrk )ᵢ^♯ & ≜ \{ α ⋅ \brk{i} ∣ α ∈ \At \} \\
  C( \comRet )ᵢ^♯ & ≜ \{ α ⋅ \ret ∣ α ∈ \At \}
 \end{align*}
 \end{definition}

Each of these base syntax elements yields a simple (finite) indexed family.
For the constructs $\command{return}$, $\command{goto}$, and $\command{break}$, all traces terminate immediately in the corresponding continuation.

We inherit the semantics of assertions and primitive actions from (G)KAT~\cite{Kozen_1997,Schmid_Kappé_Kozen_Silva_2021}. % chktex 36
Assertions have traces that accept when their only atom satisfies the test.
A primitive action $p$ yields traces of the form $\alpha p \beta \cdot \acc{i}$ for all $\alpha, \beta \in \At$ to witness that $p$ is uninterpreted: we could reach any other machine state by running $p$.
The only information retained is the value of the indicator variable, because primitive actions cannot interact with indicators.
In contrast with primitive actions, an assignment like $x := j$ has traces that accept immediately, without changing the machine state; however, each trace ends with the indicator value $j$ --- regardless of the initial indicator value $i$.

Finally, labels are encoded as no-operations, which makes them neutral for sequencing operator, i.e., we have $C( \comLabel{ℓ} )^♯ ⋄ W = W = C( \comLabel{ℓ} )^♯ ⋄ W$ for all indexed families $W$.
This is because labels serve only as potential starting points of execution; we will leverage them in the next subsection.

We now turn our attention to the program composition operators.
These are generalizations of the guarded language semantics of GKAT~\cite{Schmid_Kappé_Kozen_Silva_2021}.
First of all, the $\comITE{b}{e}{f}$ filters out traces in the semantics of the $e$ that satisfy the guard $b$, as well as the traces in $f$ that invalidate it.

 \begin{definition}[continuation semantics, branching]
 Let $e, f \in \CFGKAT$.
 We define $C( \comITE{b}{e}{f} )^♯$ as the least indexed family that satisfies the following rules for all $i \in I$:
 \begin{mathpar}
    \inferrule{
        α ∈ C( e_b ) \\
        \alpha{}w ⋅ c ∈ C( e )^♯ᵢ
    }{%
        \alpha{}w ⋅ c ∈ C( \comITE{e_b}{e}{f} )^♯ᵢ
    }
    \and
    \inferrule{
        α ∉ C( e_b ) \\
        \alpha{}w ⋅ c ∈ C( f )^♯ᵢ
    }{%
        \alpha{}w ⋅ c ∈ C( \comITE{e_b}{e}{f} )^♯ᵢ
    }
 \end{mathpar}
 \end{definition}

 The semantics of the sequencing operator is easy: it just composes the semantics of the operands with the sequencing operator we have for indexed families.
 For loops, some more care is needed because traces can be iterated, and we need to account for early termination.

 \begin{definition}[continuation semantics, sequencing and loops]%
 \label{def:intermediate-sequencing-loops}
 Let $e, f ∈ \CFGKAT$.
 We define
 \(
    C(e; f)^♯ ≜ C( e )^♯ ⋄ C( f )^♯
 \).
 Also, for all $e_b ∈ \BExp_I$, we define $C(\comWhile{e_b}{e})^♯$ as the least indexed family satisfying:
 \begin{mathpar}
    \inferrule{%
        i ∈ I \\
        α ∉ C( e_b )
    }{%
        α ⋅ \acc{i} ∈ C(\comWhile{e_b}{e})^♯ᵢ
    }
    \and
    \inferrule{%
        α ∈ C( e_b ) \\
        α w ⋅ c ∈ (C( e )^♯ ⋄ C(\comWhile{e_b}{e})^♯)ᵢ
    }{%
        α w ⋅ ⌊ c ⌋ ∈ C(\comWhile{e_b}{e})^♯_i
    }
 \end{mathpar}
 The operation $\lfloor - \rfloor$ in the last rule is defined by $\lfloor c \rfloor = \acc{i}$ when $c = \brk{i}$, and $\lfloor c \rfloor = c$ otherwise.
\end{definition}

%FIXME: We need some kind of example around here, preferably based on a program from the introduction.

The first rule accounts for traces that halt immediately because the loop guard is false.
The second rule allows prepending traces from the loop body that satisfy the guard.
Because of the way sequencing works, body traces that end in $\brk{i}$ may occur; the second rule converts their continuations to $\acc{i}$, signaling that the loop has been exited and normal control flow can resume.

\smallskip
The semantics we have so far defines the traces of a program starting from the beginning.
However, a CF-GKAT program can be started from any label.
To obtain these traces for a given label $\ell$, we must descend into the program until we encounter the corresponding label statement.
For the base cases, this is relatively simple to accomplish: just check if we start at the label.

\begin{definition}[continuation semantics starting from a label, base]
 Let $e ∈ \CFGKAT$.
 For each $ℓ ∈ L$, we define the following guarded languages with continuations:
 \begin{align*}
  C(\comAssert{e_b})ᵢ^ℓ & ≜ ∅
    & C( \comGoto{ℓ'} )ᵢ^ℓ  & ≜ ∅ \\
  C(p)ᵢ^ℓ             & ≜ ∅
    & C( \comLabel{ℓ'} )ᵢ^ℓ & ≜ \{ α ⋅ \mathbf{acc}\ i ∣ α ∈ \At,\ ℓ = ℓ' \} \\
  C(x := j)ᵢ^ℓ        & ≜ ∅
    & C( \comBrk )ᵢ^ℓ     & ≜ ∅ \\
  C( \comRet )ᵢ^ℓ     & ≜ ∅
 \end{align*}
\end{definition}
Note how none of these cases has a trace, except the one for $C( \comLabel{ℓ'} )ᵢ^ℓ$ when $\ell' = \ell$, which accepts immediately.
With these cases covered, we can then treat the inductive step.

\begin{definition}[continuation semantics starting from a label, sequencing and branching]
Let $e, f \in \CFGKAT$, $e_b \in \BExp_I$ and $\ell \in L$.
We define the following indexed families to cover the traces of CF-GKAT programs starting from the label $\ell$ when composed using branching or sequencing:
\begin{mathpar}
    C(\comITE{e_b}{e}{f})^ℓᵢ ≜ C( e )^ℓᵢ \cup C( f )^ℓᵢ
    \and
    C(e; f)^ℓᵢ ≜ (C( e )^ℓ ⋄ C( f )^♯)ᵢ \cup C( f )^ℓᵢ
\end{mathpar}
\end{definition}
For branching, the semantics starting from $\ell$ disregards the guard and descends into the operands.
The sequencing case is more interesting: here, we still need to account for the traces that start from the beginning of $f$ after executing a trace in $e$ starting from the label $ℓ$.

The only remaining case to cover is the loop.
In this case, if we start execution from a label somewhere in the body, we may need to start the loop again after completing the loop body.
On the other hand, early termination in the loop body still needs to be turned into an accepting trace.

\begin{definition}[continuation semantics starting from a label, loops]
Let $e \in \CFGKAT$ and $e_b \in \BExp_I$.
We define the indexed family $C(\comWhile{b}{e})^ℓ$ below, where $\lfloor - \rfloor$ is as in \Cref{def:intermediate-sequencing-loops}:
\[
    C(\comWhile{e_b}{e})^ℓ_i = \{ w \cdot \lfloor c \rfloor \mid w \cdot c \in (C( e )^ℓ ⋄ C(\comWhile{e_b}{e})^♯)ᵢ \}
\]
\end{definition}

\subsection{trace semantics}

The continuation semantics of a CF-GKAT program $e$ in terms of indexed families $C( e )^♯$ uses continuations to record how a trace ends.
In particular, some traces may end with the continuation of the form $\jmp{(\ell, i)}$, signaling that computation needs to continue from the label $\ell$.
But we have just seen that we can also obtain the traces of $e$ starting from $\ell$, in the form of the indexed family $C( e )^ℓ$.
This means that we have the information we need to resolve the jumping continuations, if we just put together the right traces.
We will end this section by doing just that.

To formalize our approach, we need a way to refer to the continuation semantics of a program as a whole, i.e., for all indicator values, starting from either the beginning or some label.

% FIXME: I don't think using super script here is not a good idea,
% as it doesn't align with the notation later used for λ.
% I think we should just call this jump map, name it λ and use the bracket notation.
% TK: Does the above still apply? I don't see how superscripts clash with a different notation..?

\begin{definition}
 A \emph{labeled family of guarded languages (with continuations)}, or \emph{labeled family} for short, is a function $W$ from $L + ♯$ to indexed families of guarded languages (with continuations), e.g., $W: L + ♯ → I → 𝒞$.
 We often use superscripts to denote the value at a given label $ℓ$, writing $W^ℓ$ for $G(ℓ)$.
 Note that under this convention, $W^ℓ$ is an indexed family, which means that we may further unravel by writing $W^ℓ_i$ to obtain the guarded language with continuations $G(ℓ, i)$.
\end{definition}

Crucially, we can retrofit the continuation semantics $C( e )$ as a labeled family; after all, $C( e )^♯$ is an indexed family, and so is $C( e )^ℓ$ for each $ℓ ∈ L$.
We will thus treat $C( e )$ as such from this point on.

\smallskip
To resolve the jumps in a labeled family of guarded languages with continuations, we resolve the traces ending in $\jmp{(ℓ, i)}$ by looking up the traces that originate from label $ℓ$ with indicator value $i$.
We also remove the continuations $\acc{i}$ and $\ret$, because those come with traces that either reached the end of the program, or encountered a $\comRet$ statement respectively.
Continuations of the form $\brk{i}$ should not occur at the top level when computing the semantics of a program, as they will be resolved when computing the semantics of a loop; so we can ignore them.
The result is a labeled family of guarded languages (without continuations).

\begin{definition}
 Let $W: L + ♯ → I → 𝒞$ be a labeled family of guarded languages with continuations.
 We write $W\!↓$ for the (point-wise) least labeled family of guarded languages, such that the following rules are satisfied for all $k ∈ L + ♯$, $ℓ ∈ L$, and $i, j ∈ I$:
 \begin{mathpar}
  \inferrule{%
   w ⋅ \acc{i} ∈ Wᵢᵏ
  }{%
   w ∈ W\!↓ᵢᵏ
  }
  \and
  \inferrule{%
   w ⋅ \ret ∈ Wᵢᵏ
  }{%
   w ∈ W\!↓ᵢᵏ
  }
  \and
  \inferrule{%
   wα ⋅ \jmp{(ℓ, j)} ∈ Wᵢᵏ \\
   αx ∈ W\!↓ⱼ^ℓ
  }{%
   wαx ∈ W\!↓ᵢᵏ
  }
 \end{mathpar}
\end{definition}
The first two rules take care of flattening guarded words with continuations that in acceptance,
while the third rule strings together guarded words continuations that jump to a different label.

\begin{example}
 Let $W$ be the labeled family of guarded languages with continuations defined by
 \begin{align*}
  W₁^♯ & = \{ α ⋅ \jmp{(ℓ, 1)} \}
    & W₂^♯ & = ∅ \\
  W₁^{ℓ} & = \{ α p α ⋅ \jmp{(ℓ', 1)}, β ⋅ \acc{1} \}
    & W₂^{ℓ} & = \{ α ⋅ \jmp{(ℓ', 2)} \} \\
  W₁^{ℓ'} & = \{ α q α ⋅ \jmp{(ℓ, 1)}, α r β ⋅ \jmp{(ℓ, 1)} \}
    & W₂^{ℓ'} & = \{ α ⋅ \jmp{(ℓ, 1)}\}
 \end{align*}
 Now $W\!↓₁^♯$ contains, among other things,
 the guarded word $α p α q α p α r β$.

 Note furthermore that $W\!↓₂^{ℓ}$ is empty, despite $W₂^{\ell}$ containing a guarded word with a continuation that has a mutual jump with another guarded word with continuation in $W₂^{\ell'}$, as these can never be concatenated into one guarded word with continuation of the form $\acc{i}$ or $\ret$.
\end{example}

In total, we can then obtain the semantics of a CF-GKAT term as $C( e )\!\downarrow$, in the form of a labeled family of guarded languages.
This concludes our discussion of the semantics of CF-GKAT\@.

% FIXME: Do we need this here..?
\begin{lemma}\label{the: label missing causes empty semantics}
    If \(\comLabel{ℓ}\) does not appear in expression \(e\), then \(∀ i ∈ I, C(e)ᵢ^ℓ = ∅\).
\end{lemma}

% FIXME: I think this should be conversion to GKAT automaton
\section{Decision procedure}
\label{section:decision procedure}

To establish the decision procedure, we propose CF-GKAT automata, completing the classical correspondence between program, semantics, and automaton. 
Specifically, every CF-GKAT expression can be converted to a CF-GKAT automaton via the Thompson's construction, while preserving its continuation semantics. 

Unlike GKAT automata, directly performing bisimulation on CF-GKAT automata will not yield the desired trace equivalence. 
Indeed, there exist two programs with the same trace semantics but different continuation semantics:
\begin{mathpar}
  x := 1 \and \comAssert{\true}.
\end{mathpar} 
The first program sets the indicator variable to 1, and the second program simply skips. 
The trace semantics of the above two programs are the same: both indicator assignment and skip are ``unproductive'', i.e. they will terminate immediately without executing any action.
Yet, their continuation semantics are different: \(C(x := 1)ᵢ^♯\) will constantly emit the continuation \(\acc{1}\) regardless of \(i\), but \(C(\comAssert{\true})ᵢ^♯\) will preserve starting indicator by outputting the continuation \(\acc{i}\).

Thus, our decision procedure cannot rely on bisimulation between CF-GKAT automaton; instead, we lower the CF-GKAT automata into GKAT automata. This process allows us to reuse the nearly-linear decision algorithm for GKAT automata equivalences.
Finally, the soundness and completeness of our decision procedure can be derived from a sequence of correctness results: first the correctness of Thompson's construction (\Cref{the:thompson-correctness}), then the correctness of the lowering (\Cref{the:cf-gkat-automaton-lowering-correctness}), and finally the soundness and completeness of GKAT automata equivalence~\cite{Schmid_Kappé_Kozen_Silva_2021}.

\subsection{CF-GKAT automata}

To leverage the efficient decision algorithm for GKAT automata, we will need to convert each CF-GKAT expression $e$ into a GKAT automaton that implements $C( e )\!↓$.
As we have discussed before, this process is separated into two steps, and CF-GKAT automaton serves as an crucial intermediate between CF-GKAT expressions and GKAT automata. 
In this section, we will formally define CF-GKAT automata and their continuation semantics.

Like GKAT automaton, CF-GKAT automaton is defined by a dynamics/signature~\cite{rutten_UniversalCoalgebraTheory_2000,jacobs_IntroductionCoalgebraMathematics_2016}
\begin{definition}[CF-GKAT dynamics]
 Given a set $X$, we write $D(X)$ for the set
 \[D(X) ≜ I × \At → \{\reject\} + C + K × X × I.\]
\end{definition}

Intuitively, the elements of \(D(S)\) represent possible transition behaviors in a CF-GKAT automaton over a state set $S$.
Given a current indicator value \(i ∈ I\) and an atom $α$ accounting for the truth value of each primitive test, a dynamic $ρ ∈ D(S)$ may either:
\begin{itemize}
 \item
       \emph{reject} the input, represented by $ρ(i, α) = \reject$;
 \item
       offer a \emph{continuation}, represented by $ρ(i, α) ∈ C$; or
 \item
       execute a primitive action in $K$ and set a new indicator value from $I$ while transitioning to a new state in $S$, represented by $ρ(i, α) ∈ K × X × I$.
\end{itemize}

Then the definition of CF-GKAT automaton is similar to GKAT automaton, except we will need a function \(λ: L → D(S)\) where \(λ(ℓ)\) provides a dynamics representing the ``entry point'' for label \(ℓ\).
\begin{definition}
 A \emph{CF-GKAT automaton} \(A ≜ ⟨S, δ, \hat{s}, λ⟩\) consists of a set of \emph{states} \(S\), a \emph{transition function} \(δ: S → D(S)\),
 a \emph{start state} \(\hat{s} ∈ S\), and a \emph{jump map} \(λ: L → D(S)\).
\end{definition}

Intuitively, the transition map \(δ\) assigns every state in $S$ a dynamics from $D(S)$. The jump map $λ$, on the other hand, assign a dynamics for each label $ℓ ∈ L$, indicating how to resume the computation after a \(\jmp{ℓ, i}\) continuation is reached.

\begin{example}[A simple CF-GKAT automaton]
  Consider the following program \[\comITE{b}{\{\comLabel{ℓ}; p\}}{\comGoto{ℓ}},\] then we can construct the following automaton that have the same behavior as the program 
  %FIXME: probably better diagram?
  \[\begin{tikzcd}[row sep=small]
    {} & {\hat{s}} & s & {} \\
    & {} & {}
    \arrow[shorten <=8pt, from=1-1, to=1-2]
    \arrow["{b/p}", from=1-2, to=1-3]
    \arrow["\overline{b}/\jmp{ℓ}"'{pos=1}, Rightarrow, from=1-2, to=2-2]
    \arrow["b/\acc{i}"{pos=0.5}, shorten >=15pt, Rightarrow, from=1-3, to=1-4]
    \arrow["\overline{b}/\acc{i}"{pos=1}, Rightarrow, from=1-3, to=2-3]
  \end{tikzcd}\]
  where \(ŝ \xrightarrow{b/p} s\) means that \(δ(ŝ, i, b) = (s, p)\) and \(ŝ ⇒^{\overline{b}/\acc{i}}\) means that \(δ(ŝ, i, \overline{b}) = \acc{i}\).
  In the above automaton, where the start state is \(ŝ\), 
  \begin{itemize}
    \item If the input atom is \(b\), then it will transition to the state \(s\), while executing \(p\);
    then the state \(s\) will always accept.
    \item If the input atom is \(\overline{b}\), then it will simply accept the input without executing any action.
  \end{itemize}
  As we can see, the behavior of \(ŝ\) indeed matches the behavior of the program when executing from the start.
  Then the entry dynamics for \(ℓ\) can be defined as follows:
  \[λ(ℓ, i, α) ≜ (p, s, i).\]
  To put the above definition into words: when jump to the label \(ℓ\), we will reach the state \(s\) while executing \(p\); then \(s\) will halt regardless of the condition.
  Thus, the behavior of \(λ(ℓ)\) matches the behavior of the program when executing starting from the label \(ℓ\).
\end{example}

To formalize the intuition of ``behaviors'' in the previous example. We can assign a continuation semantics to each CF-GKAT automaton \(A ≜ ⟨S, δ, ŝ, λ⟩\).
Before that, it is convenient to first define the semantics for each dynamics in \(D(S)\).

\begin{definition}[continuation semantics]
 Given an automaton \(A ≜ ⟨S, δ, \hat{s}, λ⟩\),
 the continuation semantics of each dynamics \(ρ ∈ D(S)\) is
 a family \(C(ρ)_A: I → 𝒞\),
 defined as the (point-wise) smallest set satisfying the following rules for $i, j ∈ I$ and $α ∈ \At$:
 \begin{mathpar}
  \inferrule{%
   ρ(i, α) = \acc{j}
  }{%
   α ⋅ \acc{j} ∈ (C(ρ)_A)ᵢ
  }
  \and
  \inferrule{%
   ρ(i, α) = \brk{j}
  }{%
   α ⋅ \brk{j} ∈ (C(ρ)_A)ᵢ
  }
  \and
  \inferrule{%
   ρ(i, α) = \ret
  }{%
   α ⋅ \ret ∈ (C(ρ)_A)ᵢ
  }
  \\
  \inferrule{%
   ρ(i, α) = \jmp{(ℓ, j)}
  }{%
   α ⋅ \jmp{(ℓ, j)} ∈ (C(ρ)_A)ᵢ
  }
  \and
  \inferrule{%
   ρ(i, α) = (p, s, j) \\
   w ∈ (C(δ(s))_A)ⱼ
  }{%
   αpw ∈ (C(ρ)_A)ᵢ
  }
 \end{mathpar}
 Similar to the continuation semantics of expressions, the continuations semantics of automata are also labeled families of guarded languages with continuations. Specifically, the semantics from the start \(C(A)^♯\) is defined by the dynamics of the start state, and the semantics of a label \(ℓ ∈ L\) is defined by the jump map: 
 \begin{mathpar}
  C( A )^♯ = C( δ( ŝ ) )_A, \and 
  C( A )^ℓ = C( λ(ℓ) )_A \text{ for } ℓ ∈ L.
 \end{mathpar}
\end{definition}

\subsection{Lowering CF-GKAT automata to GKAT automata}\label{sec:lowering-cf-gkat-automata-to-gkat}

The process to lower a CF-GKAT automaton $⟨S, δ, \hat{s}, λ⟩$ into a GKAT automaton consists of two different components.
First, we "embed" the indicator values into the state set; the new state set then becomes $S × I$.
Second, we resolve all the continuations in transition results.
In particular, we need to resolve the jump continuations using the jump map $λ$: when $δ(s, i, α) = \jmp{(ℓ, j)}$, the $α$-transition leaving the state $(s, i)$ in the resulting GKAT automaton is determined by looking at the $α$-behavior starting from the label $ℓ$ with indicator value $j$, given by $λ(ℓ, j, α)$.

The main obstacle to properly resolve jump continuation is that $λ(ℓ, j, α)$ may itself point to a different label by returning $\jmp{(ℓ', k)}$, then \(λ(ℓ', k, α)\) may also yield a another jump, et cetera.
These jump sequences can be resolved by iterating the jump map, and terminate when either the result is no longer a jump, or a infinite loop is detected.

\begin{definition}[iteration lifting]\label{def: iteration lifting}
  Given a function \(h: X → X + \{\reject\} + E\), where \(X\) is a finite set
  and \(\{\reject\} + E\) specifies the ``exit results'',
  then this function can be lifted to \(\iter(h)\) by iterating \(h\).
  We will use \(M\) to keep track of the explored value of \(M\):
  \begin{align*}
  \iter'(h) & : 2^X → X → \{\reject\} + E \\
  \iter'(h) & (M)(m) ≜ \begin{cases}
      \reject & \text{if } m ∈ M  \\
      h(m) & \text{if } m ∉ M \text{ and } h(m) ∈ \{\reject\} + E \\
      \iter'(h)(M ∪ \{m\})(h(m)) & \text{if } m ∉ M \text{ and } h(m) ∈ X
    \end{cases};
  \intertext{and \(\iter\) defined as supplying \(∅\) as the starting point of \(M\):}
    \iter(h) & : X → \{\reject\} + E \\
    \iter(h) & ≜ \iter'(h)(∅)
  \end{align*}
  To improve clarity, in the definition of \(h\),
  we will write \(\injL : X → X + \{\reject\} + E\) as \(\contWith\),
  to indicate the iteration will continue;
  and write \(\injR: \{\reject\} + E → X + \{\reject\} + E\) as \(\exitWith\),
  to indicate the iteration will be exited.
\end{definition}
Intuitively, \(M\) keeps track of all the explored value in \(X\),
and if a input has already been explored,
then rejection \(\reject\) will be returned to indicate a infinite loop;
as unproductive infinite iterations will not produce any observable trace.
Indeed, GKAT treats un-productive infinite iterations
in the \command{while} loops with the same strategy~\cite{Schmid_Kappé_Kozen_Silva_2021}.
On the other hand, if \(h(m)\) falls into the exit set \(\{\reject\} + E\),
then \(\iter(h)\) will stop and return \(h(m)\).
Finally, if the \(h(m)\) fall into \(X\), then \(\iter(h)\) will continue the loop with \(h(m)\) as input, and mark \(m\) as explored.
Notice that \(\iter(h)\) will be total when \(h\) is total,
because \(X\) is a finite set.

In the specific case of jump resolution,
the iteration will continue when the result of \(λ\) is a jump, but exit otherwise.

\begin{definition}[Jump resolution]
 Let $S$ be a finite set, and let $λ∶ L → D(S)$ be a jump function.
 We define the resolved jump map ${λ\!↓}: L → D(S)$, as follows:
 \[
  λ\!↓ = \iter \left(
    (ℓ, i, α) ↦ \begin{cases}
      \contWith (ℓ', i', α) & λ(ℓ, i, α) = \jmp{(ℓ', i')} \\
      \exitWith (λ(ℓ, i, α)) & \text{otherwise}
    \end{cases}
  \right)
 \]
\end{definition}

Notice that \(λ\!↓\) resolves the internal jumps continuation in \(λ\); concretely the return of \(λ\!↓\) will never be a jump continuation. 
Intuitively, the continuation resolution is separated into two procedure: we first replace all the jump continuation with the dynamics \(λ\!↓\) to obtain \(δ'\), and then we will resolve the other continuation in \(δ'\) as both accept or reject to obtain the lowered transition function, namely \(δ\!↓\). Formally, the lowering is defined as follows:

\begin{definition}[Lowering CF-GKAT automata]
 Given a CF-GKAT automaton \(A ≜ ⟨S, δ, \hat{s}, λ⟩\), and $i ∈ I$, we define the GKAT automaton \({𝐴\!↓ᵢ} ≜ ⟨S × I, δ\!↓, (s, i)⟩\), where $δ\!↓$ is given in two steps:
 \begin{align*}
  δ'((s, i), α) & ≜
    \begin{cases}
      λ\!↓(ℓ, i, α) & δ(q, i, α) = \jmp{(ℓ, i)} \\
      δ(q, i, α) & \text{otherwise}
    \end{cases}\\
  δ\!↓((s, i), α) & ≜
  \begin{cases}
    % \mathrlap and \hphantom is used for alignment purpose
    % the \mathrlap is the displayed expression
    % and \hphantom contains the "longest expression" for alignment
    \mathrlap{\reject}\hphantom{λ\!↓(ℓ, i, α)} & δ'(s, i, α) ∈ \{ \brk{j} \}\\
   \accept & δ'(s, i, α) ∈ \{ \ret, \acc{j} : j ∈ I \} \\
   δ(q, i, α) & \text{otherwise}
  \end{cases}
 \end{align*}
\end{definition}
Notice \(λ\!↓\) is total and \(δ'((s, i), α)\) will not return a jump continuation, therefore $δ\!↓$ is well-defined; in other words, for all $s ∈ S$, $i ∈ I$ and $α ∈ \At$, it holds that $δ\!↓((s, i), α) ∈ \{\reject, \accept\} + K × (S × I)$, as expected for a GKAT automaton on state set $S × I$.

Having defined our lowering operation, we can state its correctness as follows.

\begin{theorem}[Correctness of lowering]\label{the:cf-gkat-automaton-lowering-correctness}
 Let \(A ≜ ⟨S, δ, \hat{s}, λ⟩\) be a CF-GKAT automaton.
 The translation from CF-GKAT automata to GKAT automata commutes with the semantic jump resolution operator, in the sense that for $i ∈ I$, it holds that $G(A\!↓_i) = C(A)\!↓^♯ᵢ$.
\end{theorem}

\subsection{Converting expressions to CF-GKAT automata}

The final piece of our puzzle is to convert CF-GKAT expressions to CF-GKAT automata.
To accomplish this, we generalize a construction proposed for GKAT, which turns a GKAT expression into a GKAT automaton in a trace-equivalent manner~\cite{Schmid_Kappé_Kozen_Silva_2021}.
This construction proceeds by induction on the structure of the expression and was inspired by Thompson's construction to obtain a non-deterministic finite automaton from a regular expression~\cite{thompson_ProgrammingTechniquesRegular_1968}, which is why we refer to it as the \emph{Thompson construction for CF-GKAT}.

In contrast to the original Thompson's construction, the Thompson's construction for GKAT produces a GKAT automaton with a \emph{start dynamics} instead of an explicit start state. 
Although automata with start dynamics are equivalent to automata with start states; using start dynamics will help us efficiently compose automata, avoiding the silent transitions present in the original algorithm.
To take advantage of start dynamics, we will define \emph{CF-GKAT automata with start dynamics} in the following definitions:

\begin{definition}
 A CF-GKAT automaton with start dynamics \(A ≜ ⟨S, δ, ι, λ⟩\) consists of $S$, $δ$ and $λ$ as in a CF-GKAT automaton, in addition to a start dynamics \(ι ∈ D(S)\).
\end{definition}

We elide the definition of the semantics for CF-GKAT automata with start dynamics for the sake of brevity.
Suffice it to say that they can be easily converted to a plain CF-GKAT automata by adding a start state \(\hat{s}\) that takes the start dynamics:
\begin{equation}\label{cons: CF-GKAT pseudo start to CF-GKAT automata}
 ⟨S, δ, ι, λ⟩ ↦ ⟨S + \hat{s}, δ_ι, \hat{s}, λ⟩,
 \text{ where }
 δ_ι(i, s, α) ≜
 \begin{cases}
  ι(i, α)    & \text{if } s = \hat{s} \\
  δ(s)(i, α) & \text{if } s ≠ \hat{s}
 \end{cases}
\end{equation}


% FIXME: The syntax in the expression column is the compact one... we probably want to change that - T
% FIXME: CZ: we don't have enough space, we need to think about this.
\begin{table}
  \centering
  \begin{tabular}{c || c | l | l | l}
   \(e\)  & \(S\) & \(δ(s)\) & \(ι(i, α)\) & \(λ(ℓ)\) \\[5px]
   \hline
   \(\comAssert{e_b}\)& \(∅\)& \(!\)& \(
   \begin{cases}
    \acc{i} & (α, i) ∈ C( e_b )   \\
    \reject       & \text{otherwise}
   \end{cases}
   \) & \(\reject\) \\[20px]
   %
   \(x := i'\) & \(∅\) & \(!\) & \(\acc{i}\) & \(\reject\) \\[20px]
   \(p\) & \(\{*\}\) & \(\acc{i}\) & \((p, *, i)\) & \( \reject \) \\[20px]
   \(\comRet\) & \(∅\) & \(!\) & \(\ret\) & \(\reject\) \\[20px]
   \(\comBrk\) & \(∅\) & \(!\) & \(\brk{i}\) & \(\reject\) \\[20px]
   \(\comGoto{ℓ}\) & \(∅\) & \(!\) & \(\jmp{(ℓ, i)}\) & \(\reject\) \\[20px]
   \(\comLabel{ℓ'}\) & \(∅\) & \(!\)  & \(\acc{i}\) &
    \(\begin{cases}
      \acc{i} & ℓ = ℓ' \\
      \reject    & \text{otherwise}
     \end{cases}
   \)\\[25px]
   %
   \(e₁ +_{e_b} e₂\) & \(S₁ + S₂\) & \(
   \begin{cases}
    δ₁(s) & s ∈ S₁ \\
    δ₂(s) & s ∈ S₂
   \end{cases}
   \) & \(
   \begin{cases}
    ι₁(i, α) & (α, i) ∈ C( e_b ) \\
    ι₂(i, α) & (α, i) ∉ C( e_b )
   \end{cases}
   \) & \(
   \begin{cases}
    λ₁(ℓ) & \text{\(ℓ\) in \(e₁\)} \\
    λ₂(ℓ) & \text{\(ℓ\) in \(e₂\)} \\
    \reject & \text{otherwise}
   \end{cases}
   \)\\[30px]
   %
   \(e₁ ⋅ e₂\) & \(S₁ + S₂\) & \(
   \begin{cases}
    δ₁(s)[ι₂] & s ∈ S₁ \\
    δ₂(s)      & s ∈ S₂
   \end{cases}
   \) & \( ι₁[ι₂](i, α) \) & \(
   \begin{cases}
    λ₁(ℓ)[ι₂] & \text{\(ℓ\) in \(e₁\)} \\
    λ₂(ℓ) & \text{\(ℓ\) in \(e₂\)} \\
    \reject & \text{otherwise}
   \end{cases}
   \) \\[30px]
   %
   \({e₁}^{(e_b)}\)
   & \(S_{e₁}\)
   & \(⌊δ₁(s)[ι₁^{e_b}]⌋\)
   & \(⌊ι₁^{e_b}⌋(i, α)\)
   & \( ⌊ λ(ℓ)[ι₁^{e_b}] ⌋ \) \\[10px]
  \end{tabular}
  %FIXME: CZ: I don't feel like we need a new notation 0
  \caption{Thompson's construction for CF-GKAT. Here,
  \(!\) denotes the unique function \(!: ∅ → X\) for any $X$,
  and $\reject, \acc{i}$, depends on the type, sometimes will denote the constant $\reject, \acc{i}$ function}
  \label{tab: thompson's construction}
\end{table}

Thompson's construction turns a CF-GKAT expression \(e\) to a CF-GKAT automaton with start dynamics.
We call the result of said construction \emph{the Thompson's automaton} for \(e\).
The following paragraphs describe the construction and intuition behind Thompson's construction by cases, and \cref{tab: thompson's construction} serves as a summary; we will use \(A₁ ≜ ⟨S₁, δ₁, ι₁, λ₁⟩\) and \(A₂ ≜ ⟨S₂, δ₂, ι₂, λ₂⟩\) to denote the Thompson's automata for \(e₁\) and \(e₂\) respectively.
Finally, to obtain a CF-GKAT automaton with the same continuation semantics as \(e\), we will convert the Thompson's automaton of \(e\) to CF-GKAT automaton by construction \labelcref{cons: CF-GKAT pseudo start to CF-GKAT automata}.

%FIXME: CZ: I think all the following paragraphs should have formally defined the thompson's construction using notation. And the table should only be used as a reference.
% in this way we can make the table more compact.
\subsubsection*{Converting \comBrk, \comRet, \command{goto}, and indicator assignment:}
recall the semantics of \(\comBrk\), \(\comRet\), \(\comGoto{ℓ}\), and indicator assignments will simply emit the corresponding continuations.
Thus, the Thompson's automata for these commands consist only of a start dynamic which yields the desired continuation.

\subsubsection*{Converting tests and primitive actions:}
the conversions of primitive tests and primitive actions largely inherit the Thompson's construction for GKAT.
The Thompson's automaton for tests \(e_b\) will contain only a start dynamic, which will accept the input indicator-atom pairs if and only if they satisfy \(e_b\).
The Thompson's automata for primitive actions \(p\) will contain a start dynamic that always transition to the unique state while executing the action \(p\), then the unique state will accept all inputs.

\subsubsection*{Converting labels:}
recall that \(\comLabel{ℓ'}\) is a non-operation when computing the semantics from the start of the program, i.e. its semantics coincides with the sequential identity: \(\comAssert{\true}\).
However, the behavior of \(\comLabel{ℓ'}\) and \(\comAssert{\true}\) diverges when we consider the semantics starting from labels.
Specifically, when starting from a label \(ℓ ≠ ℓ'\),
\begin{mathpar}
  C(\comLabel{ℓ'})ᵢ^ℓ = ∅; \and
  C(\comAssert{\true})ᵢ^ℓ = \{α ⋅ \acc{i} ∣ α ∈ \At \}.
\end{mathpar}
This difference is reflected in the jump map \(λ: L → D(S)\), which specifies the entry point for each label.
In this case, the jump map will map \(ℓ'\) to the behavior of the identity operation \(\comAssert{\true}\), and map every other label to constant rejection, representing that the continuation \(\jmp{ℓ}\) will not resume from \(\comLabel{ℓ'}\) when \(ℓ' ≠ ℓ\).

% FIXME: I think this is too on the nose... Basically just reiterating the definition
\subsubsection*{Converting \command{if} statements:}
the Thompson automaton for \(\comITE{e_b}{e₁}{e₂}\) is also similar to that of GKAT:
If the input atom-indicator pair satisfies \(e_b\), the start \(ι\) will enter the Thompson automaton of \(e₁\) by taking on the behavior of \(ι₁\) ; and when the starting atom-indicator pair doesn't satisfy \(e_b\), then \(ι\) will take on the behavior of \(ι₂\).
The jump map \(λ\) assigns the entry point for label \(ℓ\) based on where \(ℓ\) appears: namely if \(ℓ\) appears in \(e₁\), then \(ℓ\) will take its entry point in \(A₁\); and similarly, if \(ℓ\) appears in \(e₂\), \(ℓ\) will take its entry point in \(A₂\).

\subsubsection*{Converting Sequencing:}
Sequencing of automata can be defined by \emph{uniform continuations}, which combines two dynamics $h₁, h₂ ∈ D(S)$ into a new dynamic \(h₁[h₂]\): the resulting dynamic acts like $h₁$ in almost all cases, except when $h₁$ accepts, then it will take on the behavior of \(h₂\).
In other word, \(h₁[h₂]\) connects all the accepting transition of \(h₁\) to \(h₂\).
Uniform continuation is typically used to compose two automata or add self-loops to an automaton; and can be formally defined as follows.
\begin{definition}[Uniform Continuation]
  Let $S$ be a set and given two dynamic $h₁, h₂ ∈ D(S)$,
  their \emph{uniform continuation} is the dynamic $h₁[h₂] ∈ D(S)$, defined as follows:
  \[
    h₁[h₂](i, α) ≜
    \begin{cases}
    h₂(i', α) & \text{if } h₁(i, α) = \acc{i'} \\
    h₁(i, α)  & \text{otherwise}
    \end{cases}
  \]
\end{definition}
To construct the Thompson's automaton for \(e₁; e₂\),
we will simply connect all the accepting transition in \(A₁\) to \(A₂\),
by applying uniform continuations on start dynamics \(ι₁\), transitions \(δ₁\), and jump map \(λ₁\); while preserving the dynamics in \(A₂\).

\subsubsection*{Converting \command{while} loops:}

Like GKAT automata, CF-GKAT automata require every transition between states to execute a primitive action.
This characteristic presents a unique challenge in defining the start dynamics for while loops.
Namely, the primitive action is not necessarily encountered in the first iteration of the loop; for example, consider 
\begin{equation}\label[prog]{prog:loop-head-iter-example}
  \begin{aligned}
    \comWhile{ & x ≠ 2}{\{\\
      & \comITE{x = 0}{x := 1 \\
      &}{\comITE{x = 1}{\{p; x := 2\} \\
      &}{\{\comAssert{\true}\}}}\\ 
      \}}
  \end{aligned}
 \end{equation}
with the input indicator \(0\), then the first primitive action \(p\) will be encountered on the second iteration of the loop.
Even worse, when starting with an indicator variable that is not in \(\{0, 1, 2\}\), the program will be stuck in an infinite loop by the skip (written as \(\comAssert{\true}\)), and never encounter its first primitive action. 

Fortunately, these difficulties can be resolved by the \(\iter\) function (\cref{def: iteration lifting}). We will iterate the loop body until we encounter a primitive action or non-local control.
\begin{definition}[Iterated Start Dynamics]
  Let $S$ be a set, let $h ∈ D(S)$, and $e_b ∈ \BExp_I$.
  We can use the \(\iter\) function to define $hᵇ: D(S)$, as follows:
  \begin{align*}
   h^{e_b} & : D(S)\\
   h^{e_b} & ≜
   \iter\left(
     (i, α) ↦
     \begin{cases}
       \exitWith(\acc{i}) & \text{if } (i, α) ∉ C(e_b) \\
       \contWith(i', α) & \text{if } (i, α) ∈ C(e_b) \text{ and } h(i, α) = \acc{i'} \\
       \exitWith(h(i, α)) & \text{otherwise}
     \end{cases}
   \right)
  \end{align*}
\end{definition}
In the first case, the input \((i, a)\) doesn't satisfy \(b\), causing the while loop to terminate.
In the second case, the loop body accepts \((i, α)\) immediately and returns the exit indicator value \(i'\), thus the iteration of loop body will continue with \((i', α)\).
And the final case is reached when the program executes an action or encounters a non-local control, then the iteration can also be stopped.

\begin{example} 
  Consider the~\cref{prog:loop-head-iter-example} above with indicator set \(\{0, 1, 2, 3\}\), primitive action \(\{p\}\), no label, and no primitive boolean.
  Then the only atom is \(∅\), and thompson's automaton \(A₁ ≜ ⟨S₁, δ₁, ι₁, λ₁⟩\) for the loop body
  \begin{align*}
    & \comITE{x = 0}{x := 1 \\
    &}{\comITE{x = 1}{\{p; x := 2\} \\
    &}{\{\comAssert{\true}\}}}
  \end{align*}
  can be computed to be following
  \[
    S₁ ≜ \{s\} \qquad 
    \begin{aligned}
      ι₁(0, ∅) & ≜ \acc{1}\\
      ι₁(1, ∅) & ≜ (p, s, 2)\\
      ι₁(2, ∅) & ≜ \acc{2}\\
      ι₁(3, ∅) & ≜ \acc{3}
    \end{aligned} \qquad
    \begin{aligned}
      δ₁(s, 0, ∅) & ≜ \acc{0}\\
      δ₁(s, 1, ∅) & ≜ \acc{1}\\
      δ₁(s, 2, ∅) & ≜ \acc{2}\\
      δ₁(s, 3, ∅) & ≜ \acc{3}
    \end{aligned} \qquad
    λ ≜ {!}
  \]
  where \(λ ≜ {!}\) is the unique function \(∅ → G(S₁)\), since the label set is empty.
  %FIXME: this derivation does not exactly follow the definition of iter, but a intuitive account
  Then the iterated start dynamics \(ι^{x≠2}\) with starting indicator \(0\) can be computed as follows:
  \begin{align*}
    ι₁^{x≠2}(0, ∅) 
    & = ι₁^{x≠2}(1, ∅) 
      & \text{because }(0, ∅) ∈ C(x ≠ 2) \text{ and } ι₁(0, ∅) = \acc{1} \\  
    & = (p, s, 2)
      & \text{because } ι₁(1, ∅) = (p, s, 2) \\
    ι₁^{x≠2}(3, ∅) 
    & = ι₁^{x≠2}(3, ∅) 
      & \text{because }(3, ∅) ∈ C(x ≠ 2) \text{ and } ι₁(3, ∅) = \acc{3} \\  
    & = \reject
      & \text{the input \((3, ∅)\) is already explored}
  \end{align*}
\end{example}

With the start dynamics defined, we still need to resolve structures within the loop body, like the \(\comBrk\)-continuation.
To perform $\comBrk$-resolution, we extend the \(⌊-⌋\) operator to dynamics.
\begin{definition}
Let $S$ be a set, and let $h ∈ D(S)$.
We define $⌊h⌋ ∈ D(S)$ by lifting \(h\) via \(⌊-⌋\) when it returns a continuation:
\[
  ⌊h⌋(i, α) = \begin{cases}
  ⌊h(i, α)⌋ & \text{if } h(i, α) ∈ C \\
  h(i, α)   & \text{otherwise}
  \end{cases}
\]
\end{definition}

Finally, the transition function \(δ\) and jump map \(λ\) can be defined by first connecting \(δ₁\) and \(λ₁\) back to start dynamics \(ι\), forming a loop in the automaton;
then resolving the \(\brk{i}\) continuations using the break resolution function \(⌊-⌋\).

% FIXME: we need an example here, based on the unproductive loop shown above - T


% FIXME: I think this is good to say, but should be in a separate remark after the construction is fully presented - T
% In the worst case, it is possible for \(I'\)
% to exhaust all of \(I\) before an infinite loop is found,
% which means computing \(γ\) can take \(|I|\) time
% for every indicate \(i\) and atoms \(α\).
% However, for a fixed atom \(α\), we can cache the result of each \(i\),
% leading to a \(|I|\)-timed algorithm to compute \(γ\) for every input \(i\).



With the Thompson's construction defined, we can state the correctness of the Thompson's construction as follows.
\begin{theorem}[Thompson's construction preserves continuation semantics]\label{the:thompson-correctness}
 Let $e ∈ \CFGKAT$, and let $A_e$ be the Thompson automaton for $e$, then \(C(e) = C(A_e)\). Specifically, unfolding the definition of continuation semantics gives us:
 \[∀ i ∈ I, ℓ ∈ \{♯\} + L, C(e)ᵢ^ℓ = C(A_e)ᵢ^ℓ\]
\end{theorem}

\subsection{Algorithm and Complexity}

With the definitions of lowering and Thompson's construction established, the decision procedure mostly follows.
Nevertheless, it remains essential to define the alphabet: \((K, B, I, L)\), representing the set of primitive actions, primitive tests, indicator values, and labels, respectively. 
We may safely restrict primitive actions, primitive tests, and labels to those explicitly present in the expression, as expanding the alphabet beyond these will preserve trace semantics. This trace perseverance can be validated through induction on the expression itself.

Indicator variables, however, exhibit unique behavior within the alphabet. If the initial indicator value is absent from the program, the program's traces may diverge from traces starting from the present indicator values.
\Cref{prog:loop-head-iter-example} is one of the witness of this phenomenon: if the initial indicator value is 0, 1, or 2, the program terminates; however, if starting from an indicator value that doesn't appear in the program, then the program will loop indefinitely. 
An even simpler example is:
\[(x = 1); q,\]
where the program executes \(p\) if the initial indicator value is 1, but rejects for indicator values not present in the program.

Fortunately, given an expression \(e\), we can demonstrate that if neither \(i\) nor \(i'\) appears in \(e\), then 
\[∀ ℓ, C(e)ᵢ^{ℓ} = C(e)_{i'}^{ℓ}.\]
Therefore, when compiling the set of indicator values, it suffices to gather indicator values that appear explicitly in the program and augment this set with a special indicator \(*\) that does not appear in the program.

We summarize our decision procedure as follows:
\begin{enumerate}
  \item Given two CF-GKAT programs \(e, f\), we first collect their alphabet \((K, B, I, L)\). We gather the sets of primitive actions \(K\), primitive tests \(B\), and labels \(L\) that are present in either program \(e\) or \(f\). 
  Additionally, we identify indicator values, encompassing those found in either \(e\) or \(f\), along with an additional indicator \(*\) that is exclusive to neither program.
  \item We then proceed to compute Thompson's automata of \(e\) and \(f\) and convert them into CF-GKAT automata, denoted as \(A_e\) and \(A_f\). 
  It is noteworthy that these automata preserve the continuation semantics (\cref{the:thompson-correctness}). Formally,
  \begin{mathpar}
    C(A_e) = C(e) \and C(A_f) = C(f)
  \end{mathpar}
  \item Subsequently, we lower both CF-GKAT automata \(A_e\) and \(A_f\) to GKAT automata \(A_e\!↓ᵢ\) and \(A_f\!↓ᵢ\) for each \(i ∈ I\). 
  According to~\cref{the:cf-gkat-automaton-lowering-correctness}, these GKAT automata exhibits the same traces as \(e\) and \(f\) starting from \(i\):
  \begin{mathpar}
    G(A_e \!↓ᵢ) = C(A_e)\!↓ᵢ = C(e)\!↓ᵢ, \and 
    G(A_f \!↓ᵢ) = C(A_f)\!↓ᵢ = C(f)\!↓ᵢ.
  \end{mathpar}
  \item Finally, run the equivalence algorithm for GKAT automata~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020} on \(A_e \!↓ᵢ\) and \(A_f \!↓ᵢ\) for each \(i ∈ I\). 
  The current algorithm will return true, when all the GKAT automata equivalence checks return true.
\end{enumerate}

The soundness and completeness of this algorithm now follow as a corollary of the corresponding properties for the decision procedure in GKAT.  
We denote the algorithm introduced above as \(\mathrm{equiv}_{\CFGKAT}\), while the decision algorithm for GKAT automata is denoted as \(\mathrm{equiv}_{\GKAT}\). Thus, we establish the equivalence:
\begin{align*}
  \mathrm{equiv}_{\CFGKAT}(e, f) 
  & ⟺ ∀ i ∈ I, \mathrm{equiv}_{\GKAT}(A_e \!↓ᵢ, A_f \!↓ᵢ)  \\
  & ⟺ ∀ i ∈ I, G(A_e \!↓ᵢ) = G(A_f \!↓ᵢ) \\
  & ⟺ ∀ i ∈ I, C(e)\!↓ᵢ = C(f)\!↓ᵢ   
  ⟺ C(e)\!↓ = C(f)\!↓.
\end{align*}
This equivalence ensures that the algorithm \(\mathrm{equiv}_{\GKAT}\) not only correctly determines whether \(e\) and \(f\) have the same trace semantics; but also guarantees that if \(e\) and \(f\) are trace equivalent, then \(\mathrm{equiv}_{\GKAT}(e, f)\) will return true.

The complexity analysis of this algorithm is straightforward. Starting with an expression \(e\), we can observe through induction that the number of states in the Thompson's automaton \(A_e\) is bounded by \(|e|\), where the size \(|e|\) represents the number of primitive actions in \(e\).
After the lowering process, each GKAT automaton \(A_e\!↓\) contains at most \(|I|×|e|\) states. 
Notably, for each \(i ∈ I\), determining the equivalence between \(A_e\!↓ᵢ\) and \(A_f\!↓ᵢ\) is accomplished in nearly linear time relative to their states (assuming a constant number of primitive tests)~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}, which is bounded by \(|I|×(|e|+|f|)\).
To verify the trace equivalence between \(e\) and \(f\), equivalence checks are required for \(A_e\!↓ᵢ\) and \(A_f\!↓ᵢ\) across all \(i∈I\). 
Therefore, the overall time complexity is nearly linear with respect to \(|I|^2 × (|e|+|f|)\). 
This implies that the algorithm's complexity scales nearly linearly with the sizes of \(e\) and \(f\), but nearly quadratically with respect to the number of the indicator values \(|I|\).