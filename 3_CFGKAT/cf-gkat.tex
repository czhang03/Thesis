
% continuations
\newcommand{\conti}[1]{\mathbf{#1}}
\newcommand{\acc}[1]{{\conti{acc} ~ #1}}  % accept with an output indicator value
\newcommand{\ret}{{\conti{ret}}}  % return, terminate the program
\newcommand{\brk}[1]{\conti{brk} ~ #1}  % break with an output indicator value
\newcommand{\jmp}[1]{{\conti{jmp} ~ #1}} % goto a label

% paper specific
\newcommand{\contWith}{\mathbf{cont}}
\newcommand{\exitWith}{\mathbf{exit}}
\newcommand{\iter}{\mathrm{iter}}
\newcommand{\const}{\mathrm{const}}


\chapter{CF-GKAT, fast control-flow verification}
\label{chapter:Conclusions}
\thispagestyle{myheadings}

% set this to the location of the figures for this chapter. it may
% also want to be ../Figures/2_Body/ or something. make sure that
% it has a trailing directory separator (i.e., '/')!
\graphicspath{{4_Conclusion/Figures/}}

\section{Motivation and Overview}

The usual baseline to reason about correctness of control-flow manipulation is \emph{trace semantics}, which can be represented by guarded languages. 
Intuitively, trace semantics abstracts the meaning of the primitive tests and actions that occur in a program, and instead focus on how tests determine which actions are performed, and in what order.

\emph{Guarded Kleene Algebra with Tests}~\cite{kozen_BohmJacopiniTheorem_2008a,Schmid_Kappé_Kozen_Silva_2021},
provides a nice (co)algebraic framework to reason about trace semantics.
For example, GKAT is able to verify nontrivial  program equivalences like
\[
 \{\ \comWhile{b}{p}\ \};\ \comWhile{s}{\{\ q;\ \comWhile{b}{p}\ \}} ≡
 \comWhile{b ∨ c}{\{\ \comITE{b}{p}{q}\ \}}
\]
Furthermore, unlike KAT, GKAT equivalence is decidable in nearly-linear time (assuming the set of primitive tests is fixed)~\cite{Schmid_Kappé_Kozen_Silva_2021}, making GKAT a practical framework to reason about trace semantics of simple \command{while}-programs.

Nevertheless, GKAT still lacks important constructs that are ubiquitous among control-flow transformation algorithms.
First, as mentioned, GKAT disregards the meaning of primitive programs and tests.
For instance, when given a program like
\begin{equation}
 \comITE{y \neq 0}{\{\ x := 42;\ p\ \}}{\{\ x := 42;\ q\ \}}%
 \label[prog]{prog: assignment inside branches}
\end{equation}
we can note that a change in the value of $x$ does not have effect on whether or not $y \neq 0$.
Hence, it should be possible to factor the assignment to $x$ out of the branches, and obtain
\begin{equation}
 x := 42;\ \comITE{y \neq 0}{p}{q}%
 \label[prog]{prog: assignment outside branches}
\end{equation}
Unfortunately, GKAT does not admit this equivalence, precisely because it is agnostic with respect to the meaning of primitive actions.
However, moving to a setting that accounts for the semantics of actions is hard, because Turing completeness — and by extension, undecidability — lurks nearby.
In fact, just considering commutativities of non-interfering statements, like 
\[(x := x + 1); (y := y + 1) = (y := y + 1); (x := x + 1), \]
the theory can be quickly become undecidable~\cite{Kozen_1996, kuznetsov_ComplexityReasoningKleene_2023, azevedodeamorim_KleeneAlgebraCommutativity_2024}.

Second, GKAT excludes non-local control-flow structures like \(\command{goto}\), \(\comBrk\), and \(\comRet\).
In a general imperative language, lacking these commands will not limit its expressivity -- indeed, these control structures can be recovered using variables~\cite{erosa-hendren-1994}.

However, lacking both variables and non-local control structures, GKAT is not able to express all control flows of real-world programs.
As a very concrete example, consider the programs below.
\Cref{prog: goto version two state automaton} has a control flow strategy based purely on labels and $\texttt{goto}$.
Meanwhile, \Cref{prog: break version two state automaton} is structured as a loop with the option to terminate early using $\comBrk$.
These programs happen to be trace equivalent (i.e., they always execute the same actions in the same order) but represent behavior not expressible in plain GKAT~\cite{kozen_BohmJacopiniTheorem_2008a,schmid_GuardedKleeneAlgebra_2021}.
\begin{align}
  & \begin{aligned}
      & \comLabel{ℓ₀};\ \comIT{\neg b}{\comGoto{ℓ₁}};\ p;\ \comIT{b}{\comGoto{ℓ₁}};\ q;\ \comGoto{ℓ₀};\ \comLabel{ℓ₁}
    \end{aligned}\label[prog]{prog: goto version two state automaton}
 \\[3pt]
  & \comWhile{b}{\{\ p;\ \comITE{¬ b}{q}{\comBrk}\ \}}
 \label[prog]{prog: break version two state automaton}
\end{align}

As it turns out, deciding equivalence between these complex programs is essential in verifying control-flow manipulation procedures.
Specifically, consider the control flow structuring phase of a decompiler~\cite{cifuentes-1994}, which is tasked with converting conditional and unconditional jumps into more conventional control flow constructs as best as possible.
\Cref{prog: goto version two state automaton} can be thought of as pseudo-assembly that models the input of this process, and \Cref{prog: break version two state automaton} is a plausible outcome.
Thus the control-flow structuring process is correct when \Cref{prog: goto version two state automaton,prog: break version two state automaton} are equivalent.

To overcome these limitations of GKAT, we propose control flow GKAT (CF-GKAT), a extension of GKAT that is capable of equating programs making use of non-local control flow and indicator variables.

First, \emph{indicator variables} can be assigned and tested against hardcoded values, and do not appear in other primitive actions and tests.
Thus, assignments like $x := 42$ are allowed, but assignments like $x := y + 1$ are not.
This addition strikes a delicate balance: it is strong enough to verify well-known control-flow transformation algorithms~\cite{yakdan_NoMoreGotos_2015,erosa-hendren-1994}, yet weak enough to still exclude general computation (keeping program equivalence decidable).

Second, we extend GKAT with non-local control-flow constructs, including \(\comGoto{\!}\), \(\comBrk\) and \(\comRet\).
However, the non-local nature of these commands prevents a compositional semantics --- after all, the precise meaning of a statement like \(\comBrk\) depends on its context.
To overcome these challenges, we propose a intermediate semantics, named \emph{continuation semantics}, which appends a continuation to every trace (\Cref{sec:continuation-semantics}). 
Specifically, at the end of the trace, the program can either accept (terminate normally), break, return, or go to a label.
Then, the trace semantics of the program can be obtained by resolving these continuations.

%FIXME: CZ: This paragraph is still bit out of place to me
Inspired by the triangular correspondence between deterministic trace semantics, GKAT, and GKAT automaton, we were able to design an automaton model for CF-GKAT, where every CF-GKAT expression can be unfolded into an CF-GKAT automaton through Thompson's construction (\Cref{tab: thompson's construction}), while preserving the continuation semantic (\Cref{the:thompson-correctness}). 
Furthermore, CF-GKAT automata and continuation semantics can be lowered into GKAT automata and trace semantics respectively, while preserving their semantic correspondence (\Cref{the:cf-gkat-automaton-lowering-correctness}). 
With the Thompson's construction and the lowering, we are able to reduce the problem of deciding trace equivalence of programs into deciding the bisimulation of two GKAT automata, which is known to be efficient~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}. 

\smallskip
As a result of these extensions, CF-GKAT is able to soundly and completely verify trace equivalence of a larger class of programs, while preserving the nearly-linear efficiency of GKAT.
For instance, it can automatically check that \Cref{prog: break version two state automaton,prog: goto version two state automaton} are equivalent to each other, and also to \Cref{prog: indicator version two state automaton} (below), which is their single-loop equivalent obtained via the Böhm-Jacopini theorem~\cite{DBLP:journals/cacm/BohmJ66}.
\begin{align}
 \begin{aligned}
   & x := 1;\ \comWhile{x \neq 0}{\{ \\
   & \qquad \comITE{x = 1 ∧ b}{\{\ p;\ x := 2\ \} \\
   & \qquad\qquad}{\comITE{x = 2 ∧ ¬ b} {\{\ q;\ x := 1\ \} \\
   & \qquad\qquad}{x := 0} }\ \}}                                 \\
 \end{aligned} \label[prog]{prog: indicator version two state automaton}
\end{align}

To put this theory to work, we implemented an proof-of-concept equivalence checker for CF-GKAT\@.
This checker is able to validate highly non-trivial program transformations, such as the aforementioned Böhm-Jacopini conversion~\cite{DBLP:journals/cacm/BohmJ66}.


\section{CF-GKAT Expression and Semantics}
%FIXME: CZ: multiple indicator variable?

In this section, we introduce the language of CF-GKAT, and gradually develop its semantics.
We begin by explaining the syntax of CF-GKAT;\@ after that, we delve into the semantics of its tests.
We then introduce the model of \emph{(labeled and indexed families of) guarded languages with continuations}, which is flattened into to a model based on \emph{guarded languages}.
Having defined these tools, we then conclude by giving a semantics to CF-GKAT programs in this model.
Along the way, we will single out and explain some of the finer points using examples.

% We fix a single indicator variable $x$, as well as a finite set $I$ of possible indicator values.

\subsection{Syntax}

The syntax of CF-GKAT consists of two levels, similar to GKAT\@.
At the bottom level, there are \emph{tests}; these are Boolean assertions that can occur as guards inside conditional statements, or within assertions that occur in the program text.
To model them, we fix a finite set of primitive tests $B$, which represent uninterpreted expressions that may or may not hold.
The full syntax is as follows.
\[
 \BExp_I ∋ e_{b}, f_{b} ::=
 \false ∣ \true ∣ b ∈ B ∣ {\color{blue}x = i\ (i ∈ I)}
 ∣ e_{b} ∨ f_{b} ∣ e_{b} ∧ f_{b} ∣ \overline{e_{b}}
\]
Compared to GKAT and KAT, tests in CF-GKAT include the \emph{indicator variable test} $x = i$ (highlighted in \textcolor{blue}{blue}) for each \emph{indicator value} $i$ drawn from a finite but fixed set of possible indicator values $I$.
As the notation suggests, this test holds when the indicator variable $x$ currently has the value $i$.
% Since the set \(I\) is finite, any complex predicate \(P\) on \(I\) can be encoded as a disjunction that enumerates all the values in \(P\)\ : \[⋁ \{(x = i) ∣ P(i)\}.\]

The top level syntax of GKAT is built using a finite set of uninterpreted commands \(K\) (the \emph{primitive actions}), as well as \emph{assertions} of the form $\comAssert{e_b}$, where $e_b \in \BExp_I$ is a boolean expression.
Expressions are composed using sequencing, \texttt{if} statements, and \texttt{while} loops.
CF-GKAT extends the base elements of the syntax with indicator variable assignments \(x := i\) (for each $i \in I$), which changes the value of the indicator variable \(x\) to \(i\).
In addition, it adds the non-local control flow commands $\comBrk$ and $\comRet$, as well as $\comGoto{\ell}$ and $\comLabel{\ell}$, where $\ell$ is taken from a fixed but finite set of labels $L$.
The full syntax is given below; constructs new compared to GKAT are highlighted in \textcolor{blue}{blue} again.
\begin{align*}
 \CFGKAT ∋ e, f ::= {}&
 \comAssert{e_b}
 ∣ p ∈ K
 ∣ {\color{blue}x := i\ (i ∈ I)}
 ∣ e; f
 ∣ \comITE{e_b}{e}{f} ∣ {} \\
 &
 \comWhile{e_b}{e}
 ∣ {\color{blue} \comBrk}
 ∣ {\color{blue} \comRet}
 ∣ {\color{blue} \comGoto{ℓ}\ (ℓ ∈ L)}
 ∣ {\color{blue} \comLabel{ℓ}\ (ℓ ∈ L)}
\end{align*}

A \emph{valid program}, or \emph{program} for short, is an expression without (1)~duplicate labels, (2)~$\command{goto}$ commands with an undefined label, or (3)~$\comBrk$ statements that occur outside a loop.
For the sake of simplicity, we assume that the reader does not require a more formal definition of this notion.

\begin{example}
 Any GKAT expression is a valid program.
 Also, \cref{prog: break version two state automaton,%
  prog: goto version two state automaton,%
  prog: indicator version two state automaton}
 from the introduction are all valid CF-GKAT expressions.
 The following expressions are \emph{not} valid programs:
 \begin{align*}
  \comLabel{ℓ}; (\comITE{t}{\comLabel{ℓ}; p}{q}) \tag{the label \(ℓ\) is defined twice} \\
  (\comWhile{\true}{p}); \comGoto{ℓ} \tag{the label \(ℓ\) is undefined} \\
  \comITE{t}{\comBrk}{p} \tag{$\comBrk$ appears outside a loop}
 \end{align*}
\end{example}

%FIXME: move to semantics
\begin{remark}
 For soundness, it is important that the indicator variable $x$ does not
 occur in any primitive test $b ∈ B$ or action $p ∈ K$.
 In other words, $x$ is completely divorced from the other actions in the program,
 and may influence execution only by affecting flow control.
\end{remark}

\subsection{Boolean semantics}

To assign a semantics to CF-GKAT expressions, we first need to talk about the semantics of the Boolean sublanguage.
Similar to GKAT~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}, the semantics of a boolean is defined as a set of program states that satisfy the boolean expression. 
The difference however is that we not only need to keep track of which primitive tests are satisfied under the boolean expression (represented by atoms), but also need to record the indicator variables that satisfy the boolean expression.

Thus, the semantics of a boolean expression is a set of indicator-atom pairs.
Formally, we can calculate the semantics of a given Boolean expression \(e_b ∈ \BExp_I\) by induction.
\begin{definition}
 We define the \emph{Boolean semantics} function $C(-): \BExp_I → 2^{I  × \At}$ inductively,
 as follows.
 \begin{align*}
  C( \false ) & ≜ ∅
    & C( t )& ≜ \{ (i, α) ∣ i ∈ I, b ≤ α \}
    & C( e_{b} ∨ f_{b} ) & ≜ C( e_{b} ) ∪ C( f_{b} ) \\
  C( \true )  & ≜ I × \At
    & C( x = i ) & ≜ \{ (i, α) ∣ α ∈ \At \}
    & C( e_{b} ∧ f_{b} ) & ≜ C( e_{b} ) ∩ C( f_{b} ) \\
  & & & & C( ¬ e_{b} ) & ≜ I × \At \setminus C( e_b )
 \end{align*}
\end{definition}
We will overload the notation \(C\) later for continuation semantics/interpretation, because the boolean semantics is a restriction of the continuation semantics to assertions.

\begin{example}
 Take $B = \{ b_1, b_2 \}$ and $I = \{ 1, 2, 3 \}$; then we can calculate that
 \[
  C( (b_1 ∨ ¬ b_2) ∧ (x = 2) ) = \{
  (b_1 b_2, 2),
  (b_1 \overline{b₂}, 2),
  (\overline{b₁} \overline{b₂}, 2)
  \}
 \]
 In other words, the test above holds in execution contexts where $b₁$ and $b₂$ are both true (first element) or both false (last element), and those where $b₁$ is true but $b₂$ is false (middle element).
 In contrast, $C( x = 1 ∧ x = 3) = ∅$, which is to say that this test does not hold in any execution context, because the indicator variable \(x\) cannot be both 1 and 3 at the same time.
\end{example}

\subsection{Guarded languages with continuations}\label{sec:continuation-semantics}

We can now turn our attention to the semantics of CF-GKAT\@.
Like (G)KAT, the semantics of CF-GKAT is given in terms of \emph{guarded languages}~\cite{Schmid_Kappé_Kozen_Silva_2021,Kozen_1997}, which are best thought of as sets of symbolic traces of the program.
Our semantics of a CF-GKAT expression will ultimately be a guarded language.
To get there, however, we will need continuation semantics, a semantics that can account for the indicator variables as well as the non-local flow control statements.
The remainder of this subsection is dedicated to explaining the domain of this continuation semantics, based on \emph{guarded words with continuations}.
Intuitively, these are guarded words equipped with a piece of information called a \emph{continuation}, which contains relevant information about how flow control continues after the program ends.
This could, for instance, tell us that the execution will continue at a location marked by a label.

The possibility of including continuation information at the end of a trace allows us to define a semantics of CF-GKAT expressions inductively.
This is especially necessary in the case of non-local control flow, because the label may occur in an entirely different part of the program whose traces have not yet been computed.
Once the continuation semantics of a CF-GKAT program is known, we can flatten it into a guarded language.

\begin{definition}
 A \emph{guarded word with continuation} is a pair $w ⋅ c$,
 where $w$ is a guarded word and $c$ is a \emph{continuation},
 which can take on one of the following forms for $i ∈ I$ and $ℓ ∈ L$:
 \begin{mathpar}
  \acc{i} \and
  \brk{i} \and
  \ret \and
  \jmp{(ℓ, i)}
 \end{mathpar}
 We write $C$ for the set of all continuations.
 A set of guarded words with continuations is a \emph{guarded language with continuations}; the set of guarded languages with continuations is written $𝒞$.
\end{definition}
Intuitively, the different types of continuation may be interpreted as follows:
\begin{itemize}
    \item
    The continuation $\acc{i}$ represents that the trace has successfully reached the end of this part of the program, with indicator value \(i\).
    Execution can be picked up if the program is put in a larger context --- e.g., if $w \cdot \acc{i}$ is a trace of $e$, then it may be combined with a trace found when $f$ is executed with indicator value $i$ to compute the semantics of $e; f$.
    \item
    A continuation of the form $\brk{i}$ signals that the trace ends by halting the loop in which it occurs.
    Execution can resume only after this loop (with indicator value $i$).
    This kind of trace cannot be composed on the right, as is done for traces with accepting continuations, because we first need to enclose it in a loop to halt; it will then be converted into $\acc{i}$.
    \item
    The continuation $\ret$ represents a trace that ends in the program halting completely.
    Traces of this kind will percolate upwards in the semantics, without changing their continuation.
    These are intended to model the $\comRet$ statement, which halts the program no matter how deeply it is nested.
    In this case, the indicator value does not matter any more.
    \item
    Finally, the continuation $\jmp{(\ell, i)}$ is put on traces that will continue executing from label $\ell$, with indicator value $i$.
    Like $\brk{i}$ and $\ret$, these traces do not compose on the right, but unlike $\brk{i}$ this continuation does not change, as jump resolution happens only at the end, when the semantics is known for the entire program.
\end{itemize}

\begin{example}
 Let $w$ be the guarded word from the previous example;
 the guarded word with continuation $w ⋅ \jmp{(ℓ₁, 2)}$
 represents a partial program trace that takes the steps represented by $w$,
 and will continue executing at the label $ℓ₁$ with an indicator value of $2$.
\end{example}

%FIXME: change L to G to avoid conflict with sets of labels

\subsection{Indexed families and sequencing}
The continuation semantics of a CF-GKAT expression takes a starting indicator value, and produces a guarded language with continuations representing the traces of that program when started with this indicator value.
This semantics is modeled by the following.
\begin{definition}
An \emph{indexed family} of guarded languages (with continuations), or ``indexed family'' for the sake of brevity, is function from $I$ to guarded languages (with continuations).
Similar to guarded languages, we use \(W, V\) to denote a family of languages.
To lighten notation, we write \(Wᵢ\) to denote \(W(i)\).
\end{definition}

Similar to guarded languages, indexed families can be composed in several ways.
In particular, we are interested in the sequencing operation and the Kleene star operation of indexed families, because these will turn out to be useful when defining the continuation semantics of CF-GKAT\@.

When sequencing two families \(W\) and \(V\), the traces in \(W_i\) with a continuation of the form $\acc{j}$ will be composed with traces in \(V_j\); traces with different continuations are copied over in full, because they do not compose on the right.
Formally, this operation is defined as follows.

\begin{definition}%
\label{def:sequencing}
 Let $W, V: I \to 𝒞$.
 We write $W ⋄ V$ for the \emph{sequencing} (or \emph{concatenation}) operation of \(W\) and \(V\), which is defined as the smallest family of guarded languages with continuations (in the pointwise order) satisfying the following rules for all $i,j ∈ I$ as well as all $ℓ ∈ L$:
 \begin{mathpar}
  \inferrule{%
   wα ⋅ \acc{j} ∈ Wᵢ \\
   αx ⋅ c ∈ Vⱼ
  }{%
   wαx ⋅ c ∈ (W ⋄ V)ᵢ
  }
  \and
  \inferrule{%
   w ⋅ c ∈ Wⱼ \\
   c \in \{ \brk{i}, \acc{i}, \jmp{(\ell, i)} \}
  }{%
   w ⋅ c ∈ (W ⋄ V)ⱼ
  }
 \end{mathpar}
\end{definition}
The first rule composes accepting traces in $W$ with traces in $V$, picking up with the indicator value where the first trace left off.
Note also that this rule requires the last atom in the trace on the left to match the first atom in the trace on the right, because we want the second trace to start from the machine state computed in the first trace.
This mirrors the \emph{coalesced product} used to define the sequential composition of guarded languages (without continuations).
The last rule ensures that traces that encountered non-local control flow within $W$ are preserved in $W ⋄ V$.

\begin{example}%
\label{example:sequencing}
 Let $I = \{1,2\}$, and let $W$ and $V$ be indexed families given by:
 \begin{align*}
  W₁ & = \{ αpβ ⋅ \brk{1},\; βpα ⋅ \acc{2} \}
    & W₂& = \{ αqβ \cdot \acc{1} \} \\
  V₁ & = \{ γqβ ⋅ \ret \}
    & V₂ & = \{ αrβ ⋅ \jmp{(ℓ₁, 1)} \}
  \intertext{
   Then we can compute that the sequencing $W ⋄ V$ is the following indexed family:
  }
  (W ⋄ V)₁ & = \{ αpβ ⋅ \brk{1},\; βpαrβ ⋅ \jmp{(ℓ₁, 1)} \}
           & (W ⋄ V)₂ & = ∅
 \end{align*}
 Here, we find that $(W ⋄ V)_1$ contains $α p β ⋅ \brk{1}$ by the second rule, because $W_1$ does.
 Furthermore, the trace $β p α ⋅ \acc{2}$ in $W_1$ is composed with $α r β ⋅ \jmp{(\ell_1, 1)}$ from $V_2$ to form $β p α r β ⋅ \jmp {(\ell_1, 1)}$ in $(W ⋄ V)_1$, by the first rule.
 The set $(W ⋄ V)_2$ is empty, because despite the fact that $αqβ ⋅ \acc{1} ⋅ \acc{1} ∈ W_2$, there is no trace in $V_2$ that starts with $β$, and so neither rule can apply.
\end{example}

\subsection{continuation semantics, from the start}
With the theory of indexed families in place, we can now define the continuation semantics $C(e)^♯$ of a CF-GKAT program $e$ in terms of an indexed family.
We start with the base cases.

\begin{definition}[continuation semantics, base]
 For all $i, j ∈ I$, we define the following sets:
 \begin{align*}
  C(\comAssert{e_b})ᵢ^♯ & ≜ \{ α ⋅ \acc{i} ∣ (i, α) ∈ C( e_b ) \}
    & C( \comGoto{ℓ} )ᵢ^♯ & ≜ \{ α ⋅ \jmp{(ℓ, i)} ∣ α ∈ \At \} \\
  C(p)ᵢ^♯             & ≜ \{α p β ⋅ \mathbf{acc}\ i ∣ α, β ∈ \At\}
    & C( \comLabel{ℓ} )ᵢ^♯ & ≜ \{ α ⋅ \acc{i} ∣ α ∈ \At \} \\
  C( x := j )ᵢ^♯ & ≜ \{ α ⋅ \acc{j} ∣ α ∈ \At \}
    & C( \comBrk )ᵢ^♯ & ≜ \{ α ⋅ \brk{i} ∣ α ∈ \At \} \\
  C( \comRet )ᵢ^♯ & ≜ \{ α ⋅ \ret ∣ α ∈ \At \}
 \end{align*}
 \end{definition}

Each of these base syntax elements yields a simple (finite) indexed family.
For the constructs $\command{return}$, $\command{goto}$, and $\command{break}$, all traces terminate immediately in the corresponding continuation.

We inherit the semantics of assertions and primitive actions from (G)KAT~\cite{Kozen_1997,Schmid_Kappé_Kozen_Silva_2021}. % chktex 36
Assertions have traces that accept when their only atom satisfies the test.
A primitive action $p$ yields traces of the form $\alpha p \beta \cdot \acc{i}$ for all $\alpha, \beta \in \At$ to witness that $p$ is uninterpreted: we could reach any other machine state by running $p$.
The only information retained is the value of the indicator variable, because primitive actions cannot interact with indicators.
In contrast with primitive actions, an assignment like $x := j$ has traces that accept immediately, without changing the machine state; however, each trace ends with the indicator value $j$ --- regardless of the initial indicator value $i$.

Finally, labels are encoded as no-operations, which makes them neutral for sequencing operator, i.e., we have $C( \comLabel{ℓ} )^♯ ⋄ W = W = C( \comLabel{ℓ} )^♯ ⋄ W$ for all indexed families $W$.
This is because labels serve only as potential starting points of execution; we will leverage them in the next subsection.

We now turn our attention to the program composition operators.
These are generalizations of the guarded language semantics of GKAT~\cite{Schmid_Kappé_Kozen_Silva_2021}.
First of all, the $\comITE{b}{e}{f}$ filters out traces in the semantics of the $e$ that satisfy the guard $b$, as well as the traces in $f$ that invalidate it.

 \begin{definition}[continuation semantics, branching]
 Let $e, f \in \CFGKAT$.
 We define $C( \comITE{b}{e}{f} )^♯$ as the least indexed family that satisfies the following rules for all $i \in I$:
 \begin{mathpar}
    \inferrule{
        α ∈ C( e_b ) \\
        \alpha{}w ⋅ c ∈ C( e )^♯ᵢ
    }{%
        \alpha{}w ⋅ c ∈ C( \comITE{e_b}{e}{f} )^♯ᵢ
    }
    \and
    \inferrule{
        α ∉ C( e_b ) \\
        \alpha{}w ⋅ c ∈ C( f )^♯ᵢ
    }{%
        \alpha{}w ⋅ c ∈ C( \comITE{e_b}{e}{f} )^♯ᵢ
    }
 \end{mathpar}
 \end{definition}

 The semantics of the sequencing operator is easy: it just composes the semantics of the operands with the sequencing operator we have for indexed families.
 For loops, some more care is needed because traces can be iterated, and we need to account for early termination.

 \begin{definition}[continuation semantics, sequencing and loops]%
 \label{def:intermediate-sequencing-loops}
 Let $e, f ∈ \CFGKAT$.
 We define
 \(
    C(e; f)^♯ ≜ C( e )^♯ ⋄ C( f )^♯
 \).
 Also, for all $e_b ∈ \BExp_I$, we define $C(\comWhile{e_b}{e})^♯$ as the least indexed family satisfying:
 \begin{mathpar}
    \inferrule{%
        i ∈ I \\
        α ∉ C( e_b )
    }{%
        α ⋅ \acc{i} ∈ C(\comWhile{e_b}{e})^♯ᵢ
    }
    \and
    \inferrule{%
        α ∈ C( e_b ) \\
        α w ⋅ c ∈ (C( e )^♯ ⋄ C(\comWhile{e_b}{e})^♯)ᵢ
    }{%
        α w ⋅ ⌊ c ⌋ ∈ C(\comWhile{e_b}{e})^♯_i
    }
 \end{mathpar}
 The operation $\lfloor - \rfloor$ in the last rule is defined by $\lfloor c \rfloor = \acc{i}$ when $c = \brk{i}$, and $\lfloor c \rfloor = c$ otherwise.
\end{definition}

%FIXME: We need some kind of example around here, preferably based on a program from the introduction.

The first rule accounts for traces that halt immediately because the loop guard is false.
The second rule allows prepending traces from the loop body that satisfy the guard.
Because of the way sequencing works, body traces that end in $\brk{i}$ may occur; the second rule converts their continuations to $\acc{i}$, signaling that the loop has been exited and normal control flow can resume.

\smallskip
The semantics we have so far defines the traces of a program starting from the beginning.
However, a CF-GKAT program can be started from any label.
To obtain these traces for a given label $\ell$, we must descend into the program until we encounter the corresponding label statement.
For the base cases, this is relatively simple to accomplish: just check if we start at the label.

\begin{definition}[continuation semantics starting from a label, base]
 Let $e ∈ \CFGKAT$.
 For each $ℓ ∈ L$, we define the following guarded languages with continuations:
 \begin{align*}
  C(\comAssert{e_b})ᵢ^ℓ & ≜ ∅
    & C( \comGoto{ℓ'} )ᵢ^ℓ  & ≜ ∅ \\
  C(p)ᵢ^ℓ             & ≜ ∅
    & C( \comLabel{ℓ'} )ᵢ^ℓ & ≜ \{ α ⋅ \mathbf{acc}\ i ∣ α ∈ \At,\ ℓ = ℓ' \} \\
  C(x := j)ᵢ^ℓ        & ≜ ∅
    & C( \comBrk )ᵢ^ℓ     & ≜ ∅ \\
  C( \comRet )ᵢ^ℓ     & ≜ ∅
 \end{align*}
\end{definition}
Note how none of these cases has a trace, except the one for $C( \comLabel{ℓ'} )ᵢ^ℓ$ when $\ell' = \ell$, which accepts immediately.
With these cases covered, we can then treat the inductive step.

\begin{definition}[continuation semantics starting from a label, sequencing and branching]
Let $e, f \in \CFGKAT$, $e_b \in \BExp_I$ and $\ell \in L$.
We define the following indexed families to cover the traces of CF-GKAT programs starting from the label $\ell$ when composed using branching or sequencing:
\begin{mathpar}
    C(\comITE{e_b}{e}{f})^ℓᵢ ≜ C( e )^ℓᵢ \cup C( f )^ℓᵢ
    \and
    C(e; f)^ℓᵢ ≜ (C( e )^ℓ ⋄ C( f )^♯)ᵢ \cup C( f )^ℓᵢ
\end{mathpar}
\end{definition}
For branching, the semantics starting from $\ell$ disregards the guard and descends into the operands.
The sequencing case is more interesting: here, we still need to account for the traces that start from the beginning of $f$ after executing a trace in $e$ starting from the label $ℓ$.

The only remaining case to cover is the loop.
In this case, if we start execution from a label somewhere in the body, we may need to start the loop again after completing the loop body.
On the other hand, early termination in the loop body still needs to be turned into an accepting trace.

\begin{definition}[continuation semantics starting from a label, loops]
Let $e \in \CFGKAT$ and $e_b \in \BExp_I$.
We define the indexed family $C(\comWhile{b}{e})^ℓ$ below, where $\lfloor - \rfloor$ is as in \Cref{def:intermediate-sequencing-loops}:
\[
    C(\comWhile{e_b}{e})^ℓ_i = \{ w \cdot \lfloor c \rfloor \mid w \cdot c \in (C( e )^ℓ ⋄ C(\comWhile{e_b}{e})^♯)ᵢ \}
\]
\end{definition}

\subsection{trace semantics}

The continuation semantics of a CF-GKAT program $e$ in terms of indexed families $C( e )^♯$ uses continuations to record how a trace ends.
In particular, some traces may end with the continuation of the form $\jmp{(\ell, i)}$, signaling that computation needs to continue from the label $\ell$.
But we have just seen that we can also obtain the traces of $e$ starting from $\ell$, in the form of the indexed family $C( e )^ℓ$.
This means that we have the information we need to resolve the jumping continuations, if we just put together the right traces.
We will end this section by doing just that.

To formalize our approach, we need a way to refer to the continuation semantics of a program as a whole, i.e., for all indicator values, starting from either the beginning or some label.

% FIXME: I don't think using super script here is not a good idea,
% as it doesn't align with the notation later used for λ.
% I think we should just call this jump map, name it λ and use the bracket notation.
% TK: Does the above still apply? I don't see how superscripts clash with a different notation..?

\begin{definition}
 A \emph{labeled family of guarded languages (with continuations)}, or \emph{labeled family} for short, is a function $W$ from $L + ♯$ to indexed families of guarded languages (with continuations), e.g., $W: L + ♯ → I → 𝒞$.
 We often use superscripts to denote the value at a given label $ℓ$, writing $W^ℓ$ for $G(ℓ)$.
 Note that under this convention, $W^ℓ$ is an indexed family, which means that we may further unravel by writing $W^ℓ_i$ to obtain the guarded language with continuations $G(ℓ, i)$.
\end{definition}

Crucially, we can retrofit the continuation semantics $C( e )$ as a labeled family; after all, $C( e )^♯$ is an indexed family, and so is $C( e )^ℓ$ for each $ℓ ∈ L$.
We will thus treat $C( e )$ as such from this point on.

\smallskip
To resolve the jumps in a labeled family of guarded languages with continuations, we resolve the traces ending in $\jmp{(ℓ, i)}$ by looking up the traces that originate from label $ℓ$ with indicator value $i$.
We also remove the continuations $\acc{i}$ and $\ret$, because those come with traces that either reached the end of the program, or encountered a $\comRet$ statement respectively.
Continuations of the form $\brk{i}$ should not occur at the top level when computing the semantics of a program, as they will be resolved when computing the semantics of a loop; so we can ignore them.
The result is a labeled family of guarded languages (without continuations).

\begin{definition}
 Let $W: L + ♯ → I → 𝒞$ be a labeled family of guarded languages with continuations.
 We write $W\!↓$ for the (point-wise) least labeled family of guarded languages, such that the following rules are satisfied for all $k ∈ L + ♯$, $ℓ ∈ L$, and $i, j ∈ I$:
 \begin{mathpar}
  \inferrule{%
   w ⋅ \acc{i} ∈ Wᵢᵏ
  }{%
   w ∈ W\!↓ᵢᵏ
  }
  \and
  \inferrule{%
   w ⋅ \ret ∈ Wᵢᵏ
  }{%
   w ∈ W\!↓ᵢᵏ
  }
  \and
  \inferrule{%
   wα ⋅ \jmp{(ℓ, j)} ∈ Wᵢᵏ \\
   αx ∈ W\!↓ⱼ^ℓ
  }{%
   wαx ∈ W\!↓ᵢᵏ
  }
 \end{mathpar}
\end{definition}
The first two rules take care of flattening guarded words with continuations that in acceptance,
while the third rule strings together guarded words continuations that jump to a different label.

\begin{example}
 Let $W$ be the labeled family of guarded languages with continuations defined by
 \begin{align*}
  W₁^♯ & = \{ α ⋅ \jmp{(ℓ, 1)} \}
    & W₂^♯ & = ∅ \\
  W₁^{ℓ} & = \{ α p α ⋅ \jmp{(ℓ', 1)}, β ⋅ \acc{1} \}
    & W₂^{ℓ} & = \{ α ⋅ \jmp{(ℓ', 2)} \} \\
  W₁^{ℓ'} & = \{ α q α ⋅ \jmp{(ℓ, 1)}, α r β ⋅ \jmp{(ℓ, 1)} \}
    & W₂^{ℓ'} & = \{ α ⋅ \jmp{(ℓ, 1)}\}
 \end{align*}
 Now $W\!↓₁^♯$ contains, among other things,
 the guarded word $α p α q α p α r β$.

 Note furthermore that $W\!↓₂^{ℓ}$ is empty, despite $W₂^{\ell}$ containing a guarded word with a continuation that has a mutual jump with another guarded word with continuation in $W₂^{\ell'}$, as these can never be concatenated into one guarded word with continuation of the form $\acc{i}$ or $\ret$.
\end{example}

In total, we can then obtain the semantics of a CF-GKAT term as $C( e )\!\downarrow$, in the form of a labeled family of guarded languages.
This concludes our discussion of the semantics of CF-GKAT\@.

% FIXME: Do we need this here..?
\begin{lemma}\label{the: label missing causes empty semantics}
    If \(\comLabel{ℓ}\) does not appear in expression \(e\), then \(∀ i ∈ I, C(e)ᵢ^ℓ = ∅\).
\end{lemma}

% FIXME: I think this should be conversion to GKAT automaton
\section{Decision procedure}
\label{section:decision procedure}

To establish the decision procedure, we propose CF-GKAT automata, completing the classical correspondence between program, semantics, and automaton. 
Specifically, every CF-GKAT expression can be converted to a CF-GKAT automaton via the Thompson's construction, while preserving its continuation semantics. 

Unlike GKAT automata, directly performing bisimulation on CF-GKAT automata will not yield the desired trace equivalence. 
Indeed, there exist two programs with the same trace semantics but different continuation semantics:
\begin{mathpar}
  x := 1 \and \comAssert{\true}.
\end{mathpar} 
The first program sets the indicator variable to 1, and the second program simply skips. 
The trace semantics of the above two programs are the same: both indicator assignment and skip are ``unproductive'', i.e. they will terminate immediately without executing any action.
Yet, their continuation semantics are different: \(C(x := 1)ᵢ^♯\) will constantly emit the continuation \(\acc{1}\) regardless of \(i\), but \(C(\comAssert{\true})ᵢ^♯\) will preserve starting indicator by outputting the continuation \(\acc{i}\).

Thus, our decision procedure cannot rely on bisimulation between CF-GKAT automaton; instead, we lower the CF-GKAT automata into GKAT automata. This process allows us to reuse the nearly-linear decision algorithm for GKAT automata equivalences.
Finally, the soundness and completeness of our decision procedure can be derived from a sequence of correctness results: first the correctness of Thompson's construction (\Cref{the:thompson-correctness}), then the correctness of the lowering (\Cref{the:cf-gkat-automaton-lowering-correctness}), and finally the soundness and completeness of GKAT automata equivalence~\cite{Schmid_Kappé_Kozen_Silva_2021}.

\subsection{CF-GKAT automata}

To leverage the efficient decision algorithm for GKAT automata, we will need to convert each CF-GKAT expression $e$ into a GKAT automaton that implements $C( e )\!↓$.
As we have discussed before, this process is separated into two steps, and CF-GKAT automaton serves as an crucial intermediate between CF-GKAT expressions and GKAT automata. 
In this section, we will formally define CF-GKAT automata and their continuation semantics.

Like GKAT automaton, CF-GKAT automaton is defined by a dynamics/signature~\cite{rutten_UniversalCoalgebraTheory_2000,jacobs_IntroductionCoalgebraMathematics_2016}
\begin{definition}[CF-GKAT dynamics]
 Given a set $X$, we write $D(X)$ for the set
 \[D(X) ≜ I × \At → \{\reject\} + C + K × X × I.\]
\end{definition}

Intuitively, the elements of \(D(S)\) represent possible transition behaviors in a CF-GKAT automaton over a state set $S$.
Given a current indicator value \(i ∈ I\) and an atom $α$ accounting for the truth value of each primitive test, a dynamic $ρ ∈ D(S)$ may either:
\begin{itemize}
 \item
       \emph{reject} the input, represented by $ρ(i, α) = \reject$;
 \item
       offer a \emph{continuation}, represented by $ρ(i, α) ∈ C$; or
 \item
       execute a primitive action in $K$ and set a new indicator value from $I$ while transitioning to a new state in $S$, represented by $ρ(i, α) ∈ K × X × I$.
\end{itemize}

Then the definition of CF-GKAT automaton is similar to GKAT automaton, except we will need a function \(λ: L → D(S)\) where \(λ(ℓ)\) provides a dynamics representing the ``entry point'' for label \(ℓ\).
\begin{definition}
 A \emph{CF-GKAT automaton} \(A ≜ ⟨S, δ, \hat{s}, λ⟩\) consists of a set of \emph{states} \(S\), a \emph{transition function} \(δ: S → D(S)\),
 a \emph{start state} \(\hat{s} ∈ S\), and a \emph{jump map} \(λ: L → D(S)\).
\end{definition}

Intuitively, the transition map \(δ\) assigns every state in $S$ a dynamics from $D(S)$. The jump map $λ$, on the other hand, assign a dynamics for each label $ℓ ∈ L$, indicating how to resume the computation after a \(\jmp{ℓ, i}\) continuation is reached.

\begin{example}[A simple CF-GKAT automaton]
  Consider the following program \[\comITE{b}{\{\comLabel{ℓ}; p\}}{\comGoto{ℓ}},\] then we can construct the following automaton that have the same behavior as the program 
  %FIXME: probably better diagram?
  \[\begin{tikzcd}[row sep=small]
    {} & {\hat{s}} & s & {} \\
    & {} & {}
    \arrow[shorten <=8pt, from=1-1, to=1-2]
    \arrow["{b/p}", from=1-2, to=1-3]
    \arrow["\overline{b}/\jmp{ℓ}"'{pos=1}, Rightarrow, from=1-2, to=2-2]
    \arrow["b/\acc{i}"{pos=0.5}, shorten >=15pt, Rightarrow, from=1-3, to=1-4]
    \arrow["\overline{b}/\acc{i}"{pos=1}, Rightarrow, from=1-3, to=2-3]
  \end{tikzcd}\]
  where \(ŝ \xrightarrow{b/p} s\) means that \(δ(ŝ, i, b) = (s, p)\) and \(ŝ ⇒^{\overline{b}/\acc{i}}\) means that \(δ(ŝ, i, \overline{b}) = \acc{i}\).
  In the above automaton, where the start state is \(ŝ\), 
  \begin{itemize}
    \item If the input atom is \(b\), then it will transition to the state \(s\), while executing \(p\);
    then the state \(s\) will always accept.
    \item If the input atom is \(\overline{b}\), then it will simply accept the input without executing any action.
  \end{itemize}
  As we can see, the behavior of \(ŝ\) indeed matches the behavior of the program when executing from the start.
  Then the entry dynamics for \(ℓ\) can be defined as follows:
  \[λ(ℓ, i, α) ≜ (p, s, i).\]
  To put the above definition into words: when jump to the label \(ℓ\), we will reach the state \(s\) while executing \(p\); then \(s\) will halt regardless of the condition.
  Thus, the behavior of \(λ(ℓ)\) matches the behavior of the program when executing starting from the label \(ℓ\).
\end{example}

To formalize the intuition of ``behaviors'' in the previous example. We can assign a continuation semantics to each CF-GKAT automaton \(A ≜ ⟨S, δ, ŝ, λ⟩\).
Before that, it is convenient to first define the semantics for each dynamics in \(D(S)\).

\begin{definition}[continuation semantics]
 Given an automaton \(A ≜ ⟨S, δ, \hat{s}, λ⟩\),
 the continuation semantics of each dynamics \(ρ ∈ D(S)\) is
 a family \(C(ρ)_A: I → 𝒞\),
 defined as the (point-wise) smallest set satisfying the following rules for $i, j ∈ I$ and $α ∈ \At$:
 \begin{mathpar}
  \inferrule{%
   ρ(i, α) = \acc{j}
  }{%
   α ⋅ \acc{j} ∈ (C(ρ)_A)ᵢ
  }
  \and
  \inferrule{%
   ρ(i, α) = \brk{j}
  }{%
   α ⋅ \brk{j} ∈ (C(ρ)_A)ᵢ
  }
  \and
  \inferrule{%
   ρ(i, α) = \ret
  }{%
   α ⋅ \ret ∈ (C(ρ)_A)ᵢ
  }
  \\
  \inferrule{%
   ρ(i, α) = \jmp{(ℓ, j)}
  }{%
   α ⋅ \jmp{(ℓ, j)} ∈ (C(ρ)_A)ᵢ
  }
  \and
  \inferrule{%
   ρ(i, α) = (p, s, j) \\
   w ∈ (C(δ(s))_A)ⱼ
  }{%
   αpw ∈ (C(ρ)_A)ᵢ
  }
 \end{mathpar}
 Similar to the continuation semantics of expressions, the continuations semantics of automata are also labeled families of guarded languages with continuations. Specifically, the semantics from the start \(C(A)^♯\) is defined by the dynamics of the start state, and the semantics of a label \(ℓ ∈ L\) is defined by the jump map: 
 \begin{mathpar}
  C( A )^♯ = C( δ( ŝ ) )_A, \and 
  C( A )^ℓ = C( λ(ℓ) )_A \text{ for } ℓ ∈ L.
 \end{mathpar}
\end{definition}

\subsection{Lowering CF-GKAT automata to GKAT automata}\label{sec:lowering-cf-gkat-automata-to-gkat}

The process to lower a CF-GKAT automaton $⟨S, δ, \hat{s}, λ⟩$ into a GKAT automaton consists of two different components.
First, we "embed" the indicator values into the state set; the new state set then becomes $S × I$.
Second, we resolve all the continuations in transition results.
In particular, we need to resolve the jump continuations using the jump map $λ$: when $δ(s, i, α) = \jmp{(ℓ, j)}$, the $α$-transition leaving the state $(s, i)$ in the resulting GKAT automaton is determined by looking at the $α$-behavior starting from the label $ℓ$ with indicator value $j$, given by $λ(ℓ, j, α)$.

The main obstacle to properly resolve jump continuation is that $λ(ℓ, j, α)$ may itself point to a different label by returning $\jmp{(ℓ', k)}$, then \(λ(ℓ', k, α)\) may also yield another jump, et cetera.
These jump sequences can be resolved by iterating the jump map, and terminate when either the result is no longer a jump, or an infinite loop is detected.

\begin{definition}[iteration lifting]\label{def: iteration lifting}
  Given a function \(h: X → X + \{\reject\} + E\), where \(X\) is a finite set
  and \(\{\reject\} + E\) specifies the ``exit results'',
  then this function can be lifted to \(\iter(h)\) by iterating \(h\).
  We will use \(M\) to keep track of the explored value of \(M\):
  \begin{align*}
  \iter'(h) & : 2^X → X → \{\reject\} + E \\
  \iter'(h) & (M)(m) ≜ \begin{cases}
      \reject & \text{if } m ∈ M  \\
      h(m) & \text{if } m ∉ M \text{ and } h(m) ∈ \{\reject\} + E \\
      \iter'(h)(M ∪ \{m\})(h(m)) & \text{if } m ∉ M \text{ and } h(m) ∈ X
    \end{cases};
  \intertext{and \(\iter\) defined as supplying \(∅\) as the starting point of \(M\):}
    \iter(h) & : X → \{\reject\} + E \\
    \iter(h) & ≜ \iter'(h)(∅)
  \end{align*}
  To improve clarity, in the definition of \(h\),
  we will write \(\injL : X → X + \{\reject\} + E\) as \(\contWith\),
  to indicate the iteration will continue;
  and write \(\injR: \{\reject\} + E → X + \{\reject\} + E\) as \(\exitWith\),
  to indicate the iteration will be exited.
\end{definition}
Intuitively, \(M\) keeps track of all the explored value in \(X\),
and if a input has already been explored,
then rejection \(\reject\) will be returned to indicate a infinite loop;
as unproductive infinite iterations will not produce any observable trace.
Indeed, GKAT treats un-productive infinite iterations
in the \command{while} loops with the same strategy~\cite{Schmid_Kappé_Kozen_Silva_2021}.
On the other hand, if \(h(m)\) falls into the exit set \(\{\reject\} + E\),
then \(\iter(h)\) will stop and return \(h(m)\).
Finally, if the \(h(m)\) fall into \(X\), then \(\iter(h)\) will continue the loop with \(h(m)\) as input, and mark \(m\) as explored.
Notice that \(\iter(h)\) will be total when \(h\) is total,
because \(X\) is a finite set.

In the specific case of jump resolution,
the iteration will continue when the result of \(λ\) is a jump, but exit otherwise.

\begin{definition}[Jump resolution]
 Let $S$ be a finite set, and let $λ∶ L → D(S)$ be a jump function.
 We define the resolved jump map ${λ\!↓}: L → D(S)$, as follows:
 \[
  λ\!↓ = \iter \left(
    (ℓ, i, α) ↦ \begin{cases}
      \contWith (ℓ', i', α) & λ(ℓ, i, α) = \jmp{(ℓ', i')} \\
      \exitWith (λ(ℓ, i, α)) & \text{otherwise}
    \end{cases}
  \right)
 \]
\end{definition}

Notice that \(λ\!↓\) resolves the internal jumps continuation in \(λ\); concretely the return of \(λ\!↓\) will never be a jump continuation. 
Intuitively, the continuation resolution is separated into two procedure: we first replace all the jump continuation with the dynamics \(λ\!↓\) to obtain \(δ'\), and then we will resolve the other continuation in \(δ'\) as both accept or reject to obtain the lowered transition function, namely \(δ\!↓\). Formally, the lowering is defined as follows:

\begin{definition}[Lowering CF-GKAT automata]
 Given a CF-GKAT automaton \(A ≜ ⟨S, δ, \hat{s}, λ⟩\), and $i ∈ I$, we define the GKAT automaton \({𝐴\!↓ᵢ} ≜ ⟨S × I, δ\!↓, (s, i)⟩\), where $δ\!↓$ is given in two steps:
 \begin{align*}
  δ'((s, i), α) & ≜
    \begin{cases}
      λ\!↓(ℓ, i, α) & δ(q, i, α) = \jmp{(ℓ, i)} \\
      δ(q, i, α) & \text{otherwise}
    \end{cases}\\
  δ\!↓((s, i), α) & ≜
  \begin{cases}
    % \mathrlap and \hphantom is used for alignment purpose
    % the \mathrlap is the displayed expression
    % and \hphantom contains the "longest expression" for alignment
    \mathrlap{\reject}\hphantom{λ\!↓(ℓ, i, α)} & δ'(s, i, α) ∈ \{ \brk{j} \}\\
   \accept & δ'(s, i, α) ∈ \{ \ret, \acc{j} : j ∈ I \} \\
   δ(q, i, α) & \text{otherwise}
  \end{cases}
 \end{align*}
\end{definition}
Notice \(λ\!↓\) is total and \(δ'((s, i), α)\) will not return a jump continuation, therefore $δ\!↓$ is well-defined; in other words, for all $s ∈ S$, $i ∈ I$ and $α ∈ \At$, it holds that $δ\!↓((s, i), α) ∈ \{\reject, \accept\} + K × (S × I)$, as expected for a GKAT automaton on state set $S × I$.

Having defined our lowering operation, we can state its correctness as follows.

\begin{theorem}[Correctness of lowering]\label{the:cf-gkat-automaton-lowering-correctness}
 Let \(A ≜ ⟨S, δ, \hat{s}, λ⟩\) be a CF-GKAT automaton.
 The translation from CF-GKAT automata to GKAT automata commutes with the semantic jump resolution operator, in the sense that for $i ∈ I$, it holds that $G(A\!↓_i) = C(A)\!↓^♯ᵢ$.
\end{theorem}

\subsection{Converting expressions to CF-GKAT automata}

The final piece of our puzzle is to convert CF-GKAT expressions to CF-GKAT automata.
To accomplish this, we generalize a construction proposed for GKAT, which turns a GKAT expression into a GKAT automaton in a trace-equivalent manner~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}.
This construction proceeds by induction on the structure of the expression, and was inspired by Thompson's construction to obtain a non-deterministic finite automaton from a regular expression~\cite{thompson_ProgrammingTechniquesRegular_1968}, which is why we refer to it as the \emph{Thompson construction for CF-GKAT}.

In contrast to the original Thompson's construction, the Thompson's construction for GKAT produces a GKAT automaton with a \emph{start dynamics} instead of an explicit start state. 
Although automata with start dynamics are equivalent to automata with start states; using start dynamics will help us efficiently compose automata, avoiding the silent transitions present in the original algorithm.
To take advantage of start dynamics, we will define \emph{CF-GKAT automata with start dynamics} in the following definition:

\begin{definition}
 A CF-GKAT automaton with start dynamics \(A ≜ ⟨S, δ, ι, λ⟩\) consists of $S$, $δ$ and $λ$ as in a CF-GKAT automaton, in addition to a start dynamics \(ι ∈ G(s)\).
\end{definition}

We elide the definition of the semantics for CF-GKAT automata with start dynamics for the sake of brevity.
Suffice it to say that they can be easily converted to a plain CF-GKAT automata by adding a start state \(\hat{s}\) that takes the behavior of the start dynamics \(ι\):
\begin{equation}\label{cons: CF-GKAT pseudo start to CF-GKAT automata}
 ⟨S, δ, ι, λ⟩ ↦ ⟨S + \hat{s}, δ_ι, \hat{s}, λ⟩,
 \qquad
 \text{where}
 \qquad
 δ_ι(s, i, α) ≜
 \begin{cases}
  ι(i, α)    & \text{if } s = \hat{s} \\
  δ(s, i, α) & \text{if } s ≠ \hat{s}
 \end{cases}
\end{equation}

Thompson's construction turns a CF-GKAT expression \(e\) to a CF-GKAT automaton with start dynamics.
We call the result of said construction \emph{the Thompson's automaton} for \(e\).
The following paragraphs describe the construction and intuition behind Thompson's construction by cases. 
We will use \(A₁ ≜ ⟨S₁, δ₁, ι₁, λ₁⟩\) and \(A₂ ≜ ⟨S₂, δ₂, ι₂, λ₂⟩\) to denote the Thompson's automata for \(e₁\) and \(e₂\) respectively; and use \({!}\) to be the unique function from the empty set \({!}: ∅ → X\).
For brevity, we will use the compact notation~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020} for \command{if}-statements and \command{while}-loop:
\begin{mathpar}
  e₁ +_b e₂ ≜ \comITE{b}{e₁}{e₂}, \and 
  e₁^{(b)} ≜ \comWhile{b}{e₁}.
\end{mathpar}
Finally, to obtain a CF-GKAT automaton with the same continuation semantics as \(e\), we will convert the Thompson's automaton of \(e\) to CF-GKAT automaton by construction \labelcref{cons: CF-GKAT pseudo start to CF-GKAT automata}.

%FIXME: CZ: I think all the following paragraphs should have formally defined the thompson's construction using notation. And the table should only be used as a reference.
% in this way we can make the table more compact.
\paragraph{Converting \comBrk, \comRet, \command{goto}, and indicator assignment:}
recall the semantics of \(\comBrk\), \(\comRet\), \(\comGoto{ℓ}\), and indicator assignments will simply emit the corresponding continuations.
Thus, the non-trivial part of these Thompson's automata are the start dynamics \(ι\), which output said continuations:
\begin{align*}
  S_{\comBrk} & ≜ ∅ &
    S_{\comRet} & ≜ ∅ &
    S_{\comGoto{ℓ}} & ≜ ∅ &
    S_{x := i} & ≜ ∅ \\
  δ_{\comBrk} & ≜ {!} &
    δ_{\comRet} & ≜ {!} &
    δ_{\comGoto{ℓ}} & ≜ {!} &
    δ_{x := i} & ≜ {!}\\
  ι_{\comBrk}(i, α) & ≜ \brk{i} &
    ι_{\comRet}(i, α) & ≜ \ret &
    ι_{\comGoto{ℓ}}(i, α) & ≜ \jmp{(ℓ, i)} &
    ι_{x := i}(i, α) & ≜ \acc{i}\\
  λ_{\comBrk}(ℓ) & ≜ ⊥ &
    λ_{\comRet}(ℓ) & ≜ ⊥ &
    λ_{\comGoto{ℓ}}(ℓ) & ≜ ⊥ &
    λ_{x := i}(ℓ) & ≜ ⊥
\end{align*}

\paragraph{Converting tests and primitive actions:}
the conversions of primitive tests and primitive actions largely inherit the Thompson's construction for GKAT.
The Thompson's automaton for tests \(\comAssert{e_b}\) will contain only a start dynamic, which accepts the input indicator-atom pairs if and only if they satisfy \(e_b\).
The Thompson's automata for primitive actions \(p\) will contain a start dynamic that always transition to the unique state while executing the action \(p\), then the unique state will accept all inputs.
\begin{align*}
  S_{\comAssert{e_b}} & ≜ ∅ &
    S_{p} & ≜ \{*\} \\
  δ_{\comAssert{e_b}} & ≜ {!} &
    δ_{p}(s, i, α) & ≜ \acc{i} \\
  ι_{\comAssert{e_b}}(i, α) & ≜ \begin{cases}
      \acc{i} & (i, α) ∈ ⟦e_b⟧ \\  
      ⊥ & (i, α) ∉ ⟦e_b⟧
    \end{cases} &
    ι_{p}(i, α) & ≜ (p, *, i) \\
  λ_{\comAssert{e_b}}(ℓ) & ≜ ⊥ &
    λ_{p}(ℓ) & ≜ ⊥ 
\end{align*}

\paragraph{Converting labels:}
recall that \(\comLabel{ℓ'}\) is a non-operation when computing the semantics from the start of the program, i.e. its semantics coincides with the sequential identity: \(\comAssert{\true}\).
However, the behavior of \(\comLabel{ℓ'}\) and \(\comAssert{\true}\) diverges when we consider the semantics starting from labels.
Specifically, when starting from a label \(ℓ ≠ ℓ'\),
\begin{mathpar}
  C(\comLabel{ℓ'})ᵢ^ℓ = ∅; \and
  C(\comAssert{\true})ᵢ^ℓ = \{α ⋅ \acc{i} ∣ α ∈ \At \}.
\end{mathpar}
because the continuation \(\jmp{(ℓ,i)}\) will not resume from \(\comLabel{ℓ'}\) when \(ℓ' ≠ ℓ\).
This difference is reflected in the jump map \(λ: L → G(S)\), which specifies the entry point for each label.
In this case, the jump map will map \(ℓ'\) to the behavior of the identity operation \(\comAssert{\true}\), and map every other label to constant rejection.
\begin{align*}
  S_{\comLabel{ℓ'}} & ≜ ∅ & 
  δ_{\comLabel{ℓ'}} & ≜ {!} \\
  ι_{\comLabel{ℓ'}}(i, α) & ≜ \acc{i} &
  λ_{\comLabel{ℓ'}}(ℓ, i, α) & ≜ \begin{cases}
    \acc{i} & ℓ = ℓ'  \\
    ⊥ & ℓ ≠ ℓ'
  \end{cases}
\end{align*}

% FIXME: I think this is too on the nose... Basically just reiterating the definition
\paragraph{Converting \command{if} statements:}
the Thompson automaton for \(\comITE{b}{e₁}{e₂}\) is also similar to that of GKAT:
If the input indicator-atom pair satisfies \(b\), the start \(ι\) will enter the Thompson automaton of \(e₁\) by taking on the behavior of \(ι₁\); and when the starting indicator-atom pair doesn't satisfy \(b\), then \(ι\) will take on the behavior of \(ι₂\).
The jump map \(λ\) assigns the entry point for label \(ℓ\) based on where \(ℓ\) appears: namely if \(ℓ\) appears in \(e₁\), then \(ℓ\) will take its entry point in \(A₁\); and similarly, if \(ℓ\) appears in \(e₂\), \(ℓ\) will take its entry point in \(A₂\).
\begin{align*}
  S_{e₁ +_b e₂} & ≜ S₁ + S₂ \\
  δ_{e₁ +_b e₂}(s) & ≜ \begin{cases}
    δ₁(s) & \text{if } s ∈ S₁ \\
    δ₂(s) & \text{if } s ∈ S₂ \\
  \end{cases} \\
  ι_{e₁ +_b e₂}(i, α) & ≜ \begin{cases}
    ι₁(i, α) & (i, α) ∈ ⟦b⟧ \\  
    ι₂(i, α) & (i, α) ∉ ⟦b⟧
  \end{cases} & \\
  λ_{e₁ +_b e₂}(ℓ, i, α) & ≜ \begin{cases}
    λ₁(ℓ, i, α) & (\comLabel{ℓ}) \text{ appears in } e₁\\
    λ₂(ℓ, i, α) & (\comLabel{ℓ}) \text{ appears in } e₂\\
    ⊥ & \text{otherwise}
  \end{cases}
\end{align*}

\paragraph{Converting Sequencing:}
Sequencing of automata can be defined by \emph{uniform continuations}, which combines two dynamics $h₁, h₂ ∈ G(S)$ into a new dynamic \(h₁[h₂]\): the resulting dynamic acts like $h₁$ in almost all cases, except when $h₁$ accepts, then it will take on the behavior of \(h₂\).
In other word, \(h₁[h₂]\) connects all the accepting transition of \(h₁\) to \(h₂\).
Uniform continuation is typically used to compose two automata or add self-loops to an automaton; and can be formally defined as follows.
\begin{definition}[Uniform Continuation]
  Let $S$ be a set and given two dynamics $h₁, h₂ ∈ G(S)$,
  their \emph{uniform continuation} is the dynamic $h₁[h₂] ∈ G(S)$, defined as follows:
  \[
    h₁[h₂](i, α) ≜
    \begin{cases}
    h₂(i', α) & \text{if } h₁(i, α) = \acc{i'} \\
    h₁(i, α)  & \text{otherwise}
    \end{cases}
  \]
\end{definition}
To construct the Thompson's automaton for \(e₁; e₂\),
we will simply connect all the accepting transition in \(A₁\) to \(A₂\),
by applying uniform continuations on start dynamics \(ι₁\), transitions \(δ₁\), and jump map \(λ₁\); while preserving the dynamics in \(A₂\).
\begin{align*}
  S_{e₁; e₂} & ≜ S₁ + S₂ &
  δ_{e₁; e₂}(s) & ≜ \begin{cases}
    δ₁(s)[ι₂] & \text{if } s ∈ S₁ \\
    δ₂(s) & \text{if } s ∈ S₂ \\
  \end{cases} \\
  ι_{e₁; e₂} & ≜ ι₁[ι₂] &
  λ_{e₁; e₂}(ℓ, i, α) & ≜ \begin{cases}
    λ₁(ℓ, i, α) & (\comLabel{ℓ}) \text{ appears in } e₁\\
    λ₂(ℓ, i, α) & (\comLabel{ℓ}) \text{ appears in } e₂\\
    ⊥ & \text{otherwise}
  \end{cases}
\end{align*}

\paragraph{Converting \command{while} loops:}
Like GKAT automata, CF-GKAT automata require every transition between states to execute a primitive action.
This characteristic presents a unique challenge in defining the start dynamics for while loops.
Namely, the primitive action is not necessarily encountered in the first iteration of the loop; for example, consider 
\begin{equation}\label[prog]{prog:loop-head-iter-example}
  \begin{aligned}
    \comWhile{ & \true}{\{\\
      & \comITE{x = 0}{x := 1 \\
      &}{\comITE{x = 1}{\comBrk \\
      &}{\{\comAssert{\true}\}}}\\ 
      \}}
  \end{aligned}
 \end{equation}
with the input indicator \(0\), then the first continuation \(\brk{1}\) will be encountered on the second iteration of the loop.
Even worse, when starting with an indicator value that does not appear in the program, like \(x = 2\), the program will enter an infinite loop and never encounter its first primitive action or continuation. 

Fortunately, these difficulties can be resolved by the \(\iter\) function (\cref{def: iteration lifting}). We can iterate the loop body until we encounter a primitive action or non-local control.
\begin{definition}[Iterated Start Dynamics]
  Let $S$ be a set, let $h ∈ G(S)$, and $e_b ∈ \BExp$.
  We can use the \(\iter\) function to define $h^{(e_b)}: G(S)$, as follows:
  \begin{align*}
   h^{(e_b)} & : G(S)\\
   h^{(e_b)} & ≜
   \iter\left(
     (i, α) ↦
     \begin{cases}
       \exitWith(\acc{i}) & \text{if } (i, α) ∉ ⟦e_b⟧ \\
       \contWith(i', α) & \text{if } (i, α) ∈ ⟦e_b⟧ \text{ and } h(i, α) = \acc{i'} \\
       \exitWith(h(i, α)) & \text{otherwise}
     \end{cases}
   \right)
  \end{align*}
\end{definition}
In the first case, the input \((i, a)\) doesn't satisfy \(b\), causing the while loop to terminate.
In the second case, the loop body accepts \((i, α)\) immediately and returns the exit indicator value \(i'\), thus the iteration of loop body will continue with \((i', α)\).
And the final case is reached when the program executes an action or encounters a non-local control, then the iteration can also be stopped.
\begin{example} [Iterated Start Dynamics]
  Consider~\cref{prog:loop-head-iter-example} above with indicator set \(\{0, 1, 2\}\), no primitive action, no label, and no primitive test.
  We use \(\true\) to denote the only atom over empty set. Thus, the  Thompson's automaton \(A₁ ≜ ⟨S₁, δ₁, ι₁, λ₁⟩\) of the loop body
  \begin{align*}
    & \comITE{x = 0}{x := 1 \\
    &}{\comITE{x = 1}{\comBrk \\
    &}{\{\comAssert{\true}\}}}
  \end{align*}
  can be computed as the following
  \begin{align*}
    && ι₁(0, \true) & ≜ \acc{1} &&&\\
    S₁ & ≜ ∅ & 
    ι₁(1, \true) & ≜ \brk{1} &
    δ₁ & ≜ {!} & 
    λ & ≜ {!}\\
    && ι₁(2, \true) & ≜ \acc{2} &&&
  \end{align*}
  %FIXME: this derivation does not exactly follow the definition of iter, but a intuitive account
  Then we compute iterated start dynamics \(ι^{(\true)}\) with input \((0,\true)\) and \((2,\true)\):
  \begin{align*}
    {ι₁}^{(\true)}(0, \true) 
    & = {ι₁}^{(\true)}(1, \true) 
      & \text{because }(0, \true) ∈ ⟦\true⟧ \text{ and } {ι₁}(0, \true) = \acc{1} \\  
    & = \brk{1}
      & \text{because } {ι₁}(1, \true) = \brk{1} \\[10px]
    {ι₁}^{(\true)}(2, \true) 
    & = {ι₁}^{(\true)}(2, \true) 
      & \text{because }(2, \true) ∈ ⟦\true⟧ \text{ and } ι₁(2, \true) = \acc{2} \\  
    & = ⊥
      & \text{because the input \((2, \true)\) is already explored}
  \end{align*}
\end{example}

With the start dynamics defined, we still need to resolve structures within the loop body, like the \(\comBrk\)-continuation.
To perform $\comBrk$-resolution, we extend the \(⌊-⌋\) operator to dynamics.
\begin{definition}
Let $S$ be a set, and let $h ∈ G(S)$.
We define $⌊h⌋ ∈ G(S)$ by lifting \(h\) via \(⌊-⌋\) when it returns a continuation:
\[
  ⌊h⌋(i, α) = \begin{cases}
  ⌊h(i, α)⌋ & \text{if } h(i, α) ∈ C \\
  h(i, α)   & \text{otherwise}
  \end{cases}
\]
\end{definition}

Finally, the transition function \(δ\) and jump map \(λ\) can be defined by first connecting \(δ₁\) and \(λ₁\) back to start dynamics \(ι\), forming a loop in the automaton;
then resolving the \(\brk{i}\) continuations using the break resolution function \(⌊-⌋\).
Formally, the Thompson's automaton for loop \(e^{(e_b)}\) can be defined as follows:
\begin{align*}
  S_{e₁^{(e_b)}} & ≜ S₁ & 
  δ_{e₁^{(e_b)}} & ≜ ⌊ δ₁(s)[{ι₁}^{(e_b)}] ⌋ &  
  ι_{e₁^{(e_b)}} & ≜ ⌊ {ι₁}^{(e_b)} ⌋ &
  λ_{e₁^{(e_b)}}(ℓ) & ≜ ⌊ λ(ℓ)[{ι₁}^{(e_b)}] ⌋
\end{align*}


% FIXME: I think this is good to say, but should be in a separate remark after the construction is fully presented - T
% In the worst case, it is possible for \(I'\)
% to exhaust all of \(I\) before an infinite loop is found,
% which means computing \(γ\) can take \(|I|\) time
% for every indicate \(i\) and atoms \(α\).
% However, for a fixed atom \(α\), we can cache the result of each \(i\),
% leading to a \(|I|\)-timed algorithm to compute \(γ\) for every input \(i\).

We will state the correctness of the Thompson's construction as follows.
\begin{theorem}[Thompson's construction preserves continuation semantics]\label{the:thompson-correctness}
  Given an expression $e ∈ \CFGKAT$, let $A_e$ be the Thompson automaton for $e$, then \(C(e) = C(A_e)\). By unfolding the definition of continuation semantics:
  \[∀ i ∈ I, ℓ ∈ \{♯\} + L, C(e)ᵢ^ℓ = C(A_e)ᵢ^ℓ\]
 \end{theorem}


% % FIXME: The syntax in the expression column is the compact one... we probably want to change that - T
% % FIXME: CZ: we don't have enough space, we need to think about this.
% \begin{table}
%   \centering
%   \renewcommand\arraystretch{2}
%   \begin{tabular}{c || c | l | l | l}
%    \(e\)  & \(S\) & \(δ(s)\) & \(ι(i, α)\) & \(λ(ℓ)\) \\
%    \hline
%    \(x := i'\) & \(∅\) & \(!\) & \(\acc{i}\) & \(\const(⊥)\) \\
%    \(\comRet\) & \(∅\) & \(!\) & \(\ret\) & \(\const(⊥)\) \\
%    \(\comBrk\) & \(∅\) & \(!\) & \(\brk{i}\) & \(\const(⊥)\) \\
%    \(\comGoto{ℓ}\) & \(∅\) & \(!\) & \(\jmp{(ℓ, i)}\) & \(\const(⊥)\) \\
%    \(\comAssert{b}\)& \(∅\)& \(!\)& \(
%    \begin{cases}
%     \acc{i} & (i, α) ∈ ⟦ b ⟧   \\
%     ⊥       & (i, α) ∉ ⟦ b ⟧ 
%    \end{cases}
%    \) & \(\const(⊥)\) \\
%    \(p\) & \(\{*\}\) & \(λ i.\const(\acc{i})\) & \((p, *, i)\) & \(\const(⊥)\) \\
%    %
%    \(\comLabel{ℓ'}\) & \(∅\) & \(!\)  & \(\acc{i}\) &
%     \(\begin{cases}
%       λ i.\const(\acc{i}) & ℓ = ℓ' \\
%       \const(⊥)    & ℓ ≠ ℓ'
%       \end{cases}
%    \)\\
%    %
%    \(e₁ +_{e_b} e₂\) & \(S₁ + S₂\) & \(
%    \begin{cases}
%     δ₁(s) & s ∈ S₁ \\
%     δ₂(s) & s ∈ S₂
%    \end{cases}
%    \) & \(
%    \begin{cases}
%     ι₁(i, α) & (i, α) ∈ ⟦ b ⟧ \\
%     ι₂(i, α) & (i, α) ∉ ⟦ b ⟧
%    \end{cases}
%    \) & \(
%    \begin{cases}
%     λ₁(ℓ) & \text{\(ℓ\) in \(e₁\)} \\
%     λ₂(ℓ) & \text{\(ℓ\) in \(e₁\)} \\
%     0 & \text{otherwise}
%    \end{cases}
%    \)\\
%    %
%    \(e₁ ⋅ e₂\) & \(S₁ + S₂\) & \(
%    \begin{cases}
%     δ₁(s)[ι₂] & s ∈ S₁ \\
%     δ₂(s)      & s ∈ S₂
%    \end{cases}
%    \) & \( ι₁[ι₂](i, α) \) & \(
%    \begin{cases}
%     λ₁(ℓ)[ι₂] & \text{\(ℓ\) in \(e₁\)} \\
%     λ₂(ℓ) & \text{\(ℓ\) in \(e₁\)} \\
%     0 & \text{otherwise}
%    \end{cases}
%    \) \\
%    %
%    \({e₁}^{(b)}\)
%    & \(S_{₁}\)
%    & \(⌊δ₁(s)[{ι₁}ᵇ]⌋\)
%    & \(⌊{ι₁}ᵇ⌋(i, α)\)
%    & \( ⌊ λ(ℓ)[{ι₁}ᵇ] ⌋ \) \\
%   \end{tabular}
%   %FIXME: CZ: I don't feel like we need a new notation 0
%   \caption{Thompson's construction for CF-GKAT. Here,
%   \(!\) denotes the unique function \(!: ∅ → X\) for any $X$, and \(\const(x)\) denotes the constant function that always return \(x\)}
%   \label{tab: thompson's construction}
% \end{table}
\subsection{Algorithm and Complexity}

With the definitions of lowering and Thompson's construction established, the decision procedure mostly follows.
Nevertheless, it remains essential to define the alphabet: \((K, B, I, L)\), representing the set of primitive actions, primitive tests, indicator values, and labels, respectively. 
We may safely restrict primitive actions, primitive tests, and labels to those explicitly present in the expression, as expanding the alphabet beyond these will preserve trace semantics. This trace perseverance can be validated through induction on the expression itself.

Indicator variables, however, exhibit unique behavior within the alphabet. If the initial indicator value is absent from the program, the program's traces may diverge from traces starting from the present indicator values.
\Cref{prog:loop-head-iter-example} is one of the witness of this phenomenon: if the initial indicator value is 0, 1, or 2, the program terminates; however, if starting from an indicator value that doesn't appear in the program, then the program will loop indefinitely. 
An even simpler example is:
\[(x = 1); q,\]
where the program executes \(p\) if the initial indicator value is 1, but rejects for indicator values not present in the program.

Fortunately, given an expression \(e\), we can demonstrate that if neither \(i\) nor \(i'\) appears in \(e\), then 
\[∀ ℓ, C(e)ᵢ^{ℓ} = C(e)_{i'}^{ℓ}.\]
Therefore, when compiling the set of indicator values, it suffices to gather indicator values that appear explicitly in the program and augment this set with a special indicator \(*\) that does not appear in the program.

We summarize our decision procedure as follows:
\begin{enumerate}
  \item Given two CF-GKAT programs \(e, f\), we first collect their alphabet \((K, B, I, L)\). We gather the sets of primitive actions \(K\), primitive tests \(B\), and labels \(L\) that are present in either program \(e\) or \(f\). 
  Additionally, we identify indicator values, encompassing those found in either \(e\) or \(f\), along with an additional indicator \(*\) that is exclusive to neither program.
  \item We then proceed to compute Thompson's automata of \(e\) and \(f\) and convert them into CF-GKAT automata, denoted as \(A_e\) and \(A_f\). 
  It is noteworthy that these automata preserve the continuation semantics (\cref{the:thompson-correctness}). Formally,
  \begin{mathpar}
    C(A_e) = C(e) \and C(A_f) = C(f)
  \end{mathpar}
  \item Subsequently, we lower both CF-GKAT automata \(A_e\) and \(A_f\) to GKAT automata \(A_e\!↓ᵢ\) and \(A_f\!↓ᵢ\) for each \(i ∈ I\). 
  According to~\cref{the:cf-gkat-automaton-lowering-correctness}, these GKAT automata exhibits the same traces as \(e\) and \(f\) starting from \(i\):
  \begin{mathpar}
    G(A_e \!↓ᵢ) = C(A_e)\!↓ᵢ = C(e)\!↓ᵢ, \and 
    G(A_f \!↓ᵢ) = C(A_f)\!↓ᵢ = C(f)\!↓ᵢ.
  \end{mathpar}
  \item Finally, run the equivalence algorithm for GKAT automata~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020} on \(A_e \!↓ᵢ\) and \(A_f \!↓ᵢ\) for each \(i ∈ I\). 
  The current algorithm will return true, when all the GKAT automata equivalence checks return true.
\end{enumerate}

The soundness and completeness of this algorithm now follow as a corollary of the corresponding properties for the decision procedure in GKAT.  
We denote the algorithm introduced above as \(\mathrm{equiv}_{\CFGKAT}\), while the decision algorithm for GKAT automata is denoted as \(\mathrm{equiv}_{\GKAT}\). Thus, we establish the equivalence:
\begin{align*}
  \mathrm{equiv}_{\CFGKAT}(e, f) 
  & ⟺ ∀ i ∈ I, \mathrm{equiv}_{\GKAT}(A_e \!↓ᵢ, A_f \!↓ᵢ)  \\
  & ⟺ ∀ i ∈ I, G(A_e \!↓ᵢ) = G(A_f \!↓ᵢ) \\
  & ⟺ ∀ i ∈ I, C(e)\!↓ᵢ = C(f)\!↓ᵢ   
  ⟺ C(e)\!↓ = C(f)\!↓.
\end{align*}
This equivalence ensures that the algorithm \(\mathrm{equiv}_{\GKAT}\) not only correctly determines whether \(e\) and \(f\) have the same trace semantics; but also guarantees that if \(e\) and \(f\) are trace equivalent, then \(\mathrm{equiv}_{\GKAT}(e, f)\) will return true.

\paragraph*{Algorithm complexity:}
We now give a rough account of the computational cost for deciding equivalence of CF-GKAT programs.
Like GKAT, we consider the primitive tests \(B\) to be fixed for the purpose of analyzing complexity; otherwise, deciding equivalence of (CF-)GKAT programs is co-NP hard~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}.

Starting with an expression \(e\), we observe that the number of states in the Thompson automaton \(A_e\) is bounded by \(|e|\), which is the size of $e$ as a term.
While computing this automaton we must bear in mind that deriving the iterated start dynamics of a loop using $\iter$ may take up to $|I|$ steps (assuming we use memoization to compute the output for each input), and this happens at most $|e|$ times.
After lowering, each GKAT automaton \(A_e\!↓\) contains at most \(|I|×|e|\) states, and computing the jump resolution using $\iter$ takes on the order of $|L| \times |I|$ steps (again using memoization). 

For each \(i ∈ I\), determining the equivalence between \(A_e\!↓ᵢ\) and \(A_f\!↓ᵢ\) is accomplished in (nearly\footnote{We omit the factor coming from the inverse Ackermann function $\hat{\alpha}(n)$, which is at most $5$ for any realistic number of states, out of consideration for the sake of simplicity.}) linear time relative to the number of states, so this check takes about \(|I|×(|e|+|f|)\) steps.
To verify trace equivalence between \(e\) and \(f\), this check is required for \(A_e\!↓ᵢ\) and \(A_f\!↓ᵢ\) across all \(i∈I\). 

Therefore, the overall time spent on the equivalence checks is on the order of \(|I|^2 × (|e|+|f|)\), while computing the automata can take roughly $|L| × |I| + |I| × (|e| + |f|)$ time. 
This implies that the algorithm's complexity scales (nearly) linearly with the sizes of \(e\) and \(f\), linearly in the size of $L$, and quadratically with respect to the number of indicator values \(|I|\).


\section{Control Flow Verification}%
\label{sec:experiments}

% Our theory can be specialized into control flow verification in two different way: first, we can decide the equivalence between a program with a flowchart, where the flowchart is represented by a GKAT automaton; second, we can directly decide the equivalence between to programs.

We hypothesize that CF-GKAT can be a useful tool to check whether two programs have the same control flow, i.e.:\ under the same circumstances, they execute the same sequence of primitive commands.
An example use case could be to validate
the \emph{control flow structuring} stage of a decompiler.
Briefly put, a decompiler is a program tasked with inferring a high-level language representation of a binary executable file.
In earlier stages, the decompiler builds a \emph{control-flow graph} from the binary, in which the vertices represent different blocks of instructions, and the edges encode how control may transfer from the end of one block to the beginning of the other.
The control flow structuring pass is tasked with inferring an equivalent representation of this control flow graph in terms of constructs like \command{if-then-else} and \command{while-do}.
A tool that validates the output of a control flow structuring algorithm could leverage CF-GKAT, by casting the control flow graph as a GKAT automaton, and comparing that to the GKAT automaton that corresponds to the inferred program.

Another use case would be to validate
the correctness of refactoring operations aimed at making code more readable by eliminating or introducing early loop termination.
In general, algorithms along these lines can never be \emph{complete} with respect to input-output equivalences, as they cannot automatically validate the correctness of refactorings that introduce or eliminate primitive commands, even when this produces a functionally equivalent program.
However, CF-GKAT should be applicable to refactoring operations that rearrange the code for the sake of improving the presentation of the control flow.

In this section, we test our hypotheses on the applicability and efficiency of CF-GKAT\@.
We start by describing our proof of concept of the proposed decision procedure.
Next, we report on a case study that reflects the two use cases described above.

\subsection{Implementation}

We target the C language as it is a widely used programming language that allows for non-local flow control.
Our implementation is written in OCaml and can be divided into two parts:
\begin{itemize}
    \item
    The \emph{front-end} converts a function defined in a C file to a CF-GKAT expression.
    This conversion is based on the \command{clangML}\footnote{\url{https://memcad.gitlabpages.inria.fr/clangml/}} project which provides OCaml bindings for the \command{clang} compiler.\footnote{\url{https://clang.llvm.org/}}
    The conversion first determines which variables, if any, qualify as indicator variables and picks one variable from the set when possible.
    Next, it lifts the C syntax tree to a CF-GKAT program, mapping (1)~all assignments and comparisons of the indicator variable to their CF-GKAT counterparts, (2)~all other primitive statements to uninterpreted actions, and (3)~all control flow constructs to the corresponding CF-GKAT operator whenever possible.
    % TODO: We should probably have a figure with an example somewhere here.
    \item
    The \emph{back-end} is responsible for compiling a CF-GKAT expression down to a GKAT automaton, and for comparing two GKAT automata.
    This GKAT automaton is derived via the Thompson construction described in \Cref{section:decision procedure}; the equivalence check for GKAT automata uses the bisimulation checking procedure proposed in~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}.
\end{itemize}

The front-end and back-end combine into a tool that accepts two C files, and checks whether the functions defined therein (paired by their name) have the same control flow.
Given that not all C programs can be faithfully converted to CF-KAT expressions, our front-end does not aim to be complete; instead, we aimed to support the transformation of a sizeable portion of the code in the GNU \command{coreutils} project to perform the experiments described in the next section.

\begin{remark}
In particular, our front-end internally converts \command{for}-loops to \command{while}-loops, and \command{do-while} loops to (partially unrolled) \command{while} loops. The former transformation is sound; the latter is admissible when the loop body does not contain \command{break} or a label, which is the case for our experiment below.
\end{remark}

\subsection{A Case Study From GNU coreutils}

\begin{figure}[hbtp]
\centering
 \begin{subfigure}{0.46\textwidth}
 \begin{lstlisting}[basicstyle=\tiny\ttfamily]
  static void mp_factor_using_pollard_rho(...) {
  mpz_t x, z, y, P;
  mpz_t t, t2;
  devmsg("...", a);
  ...
  while (mpz_cmp_ui(n, 1) != 0) {
    for (;;) {
      do {
        mpz_mul(t, x, x);
        ...
        if (k % 32 == 1) {
          mpz_gcd(t, P, n);
          if (mpz_cmp_ui(t, 1) != 0)
            goto factor_found;
          mpz_set(y, x);
        }
      } while (--k != 0);
      mpz_set(z, x);
      ...
      for (unsigned long long int i = 0; i < k; i++) {
        mpz_mul(t, x, x);
        ...
      }
      mpz_set(y, x);
    }
  factor_found:
    do {
      mpz_mul(t, y, y);
      ...
    } while (mpz_cmp_ui(t, 1) == 0);
    mpz_divexact(n, n, t);
    if (!mp_prime_p(t)) {
      devmsg("...");
      ...
    } else {
      mp_factor_insert(factors, t);
    }
    if (mp_prime_p(n)) {
      mp_factor_insert(factors, n);
      break;
    }
    mpz_mod(x, x, n);
    ...
  }
  mpz_clears(P, t2, t, z, x, y, nullptr);
}
 \end{lstlisting}
 \caption{\label{c:orig}Original code of the function.}
 \end{subfigure}
 \begin{subfigure}{0.46\textwidth}
 \begin{lstlisting}[basicstyle=\tiny\ttfamily]
void mp_factor_using_pollard_rho() {
  pact(197);
  ...
  do {
    if (pbool(83)) {
      pact(194);
    }

  } while (0);
  pact(193);
  ...
  while (pbool(83)) {
    for (;;) {
      do {
        pact(176);
        ...
        if (pbool(183)) {
          pact(182);
          if (pbool(83)) {
            goto factor_found;
          }
          pact(173);
        }

      } while (pbool(181));
      pact(180);
      ...
      for (pact(177); pbool(138); pbool(59)) {
        pact(176);
        ...
      }
      pact(173);
    }
  factor_found:
    do {
      pact(172);
      ...
    } while (pbool(83));
    pact(166);
    if (!pbool(165)) {
      do {
        if (pbool(83)) {
          pact(164);
        }
      } while (0);
      pact(163);
    } else {
      pact(161);
    }
    if (pbool(160)) {
      pact(159);
      break;
    }
    pact(158);
    ...
  }
  pact(155);
}
 \end{lstlisting}
 \caption{\label{c:blinded}``Blinded'' code of the function.}
 \end{subfigure}
 \caption{Different versions of \command{mp\_factor\_using\_pollard\_rho} in \command{factor.c}, part of GNU \command{coreutils}.}
 \vspace{3mm} % HACK
\end{figure}
\begin{figure}
 \begin{subfigure}{0.46\textwidth}
 \begin{lstlisting}[basicstyle=\tiny\ttfamily]
void mp_factor_using_pollard_rho(void) {
  pact(0xc5);
  ...
  if (pbool(0x53)) {
    pact(0xc2);
  }
  pact(0xc1);
  ...
LAB_00100a0c:
  if (pbool(0x53)) {
  LAB_00100a2d:
    pact(0xb0);
    ...
    if (pbool(0xb7)) {
      pact(0xb6);
      if (pbool(0x53))
        goto LAB_00100b47;
      pact(0xad);
    }
    if (!pbool(0xb5)) {
      pact(0xb4);
      ...
      while (pbool(0x8a)) {
        pact(0xb0);
        ...
      }
      pact(0xad);
    }
    goto LAB_00100a2d;
  }
LAB_00100c34:
  pact(0x9b);
  return;
LAB_00100b47:
  do {
    pact(0xac);
    ...
  } while (pbool(0x53));
  pact(0xa6);
  if (!pbool(0xa5)) {
    if (pbool(0x53)) {
      pact(0xa4);
    }
    pact(0xa3);
  } else {
    pact(0xa1);
  }
  if (pbool(0xa0)) {
    pact(0x9f);
    goto LAB_00100c34;
  }
  pact(0x9e);
  ...
  goto LAB_00100a0c;
}
 \end{lstlisting}
 \caption{\label{c:ghidra}Code of the Ghidra's decompilation of the function.}
 \end{subfigure}
 \begin{subfigure}{0.46\textwidth}
 \begin{lstlisting}[basicstyle=\tiny\ttfamily]
void mp_factor_using_pollard_rho() {
  int factor_found = 0;
  pact(197);
  ...
  do {
    if (pbool(83)) {
      pact(194);
    }
  } while (0);
  pact(193);
  ...
  while (pbool(83)) {
    for (; factor_found == 0;) {
      do {
        pact(176);
        ...
        if (pbool(183)) {
          pact(182);
          if (pbool(83)) {
            factor_found = 1;
          }
          if (factor_found == 0)
            pact(173);
        }
      } while ((factor_found == 0) && pbool(181));
      if (factor_found == 0) {
        pact(180);
        ...
        for (pact(177); pbool(138); pbool(59)) {
          pact(176);
          ...
        }
        pact(173);
      }
    }
    factor_found = 0;
    do {
      pact(172);
      ...
    } while (pbool(83));
    pact(166);
    if (!pbool(165)) {
      do {
        if (pbool(83)) {
          pact(164);
        }
      } while (0);
      pact(163);
    } else {
      pact(161);
    }
    if (pbool(160)) {
      pact(159);
      break;
    }
    pact(158);
    ...
  }
  pact(155);
}
 \end{lstlisting}
 \caption{\label{c:calipso}Code of the function with \command{goto}s removed by \command{Calipso}.}
 \end{subfigure}
 \caption{Different versions of the function \command{mp\_factor\_using\_pollard\_rho} in \command{factor.c}, part of GNU \command{coreutils}.}
\end{figure}

% We tested our implementation by attempting to validate the results of certain program transformations.
% In each experiment we take a function body, apply a code transformation, and then check whether our implementation can certify that the input code has the same control flow as the output code.

We used GNU \command{coreutils} as a source of C code containing non-local control flow.
%
As is customary with projects of this size, the code is organized into several files that collectively define thousands of functions, ranging from very simple to very complex, that implement utilities commonly found in POSIX systems.
%
%FIXME: I think it is helpful to describe the code size (number of lines) and the complex structure the function has.
Throughout this section, we will use the function \command{mp\_factor\_using\_pollard\_rho} in \command{factor.c} as an example of the validation machinery we built on top of CF-GKAT. The code in Figure~\ref{c:orig} shows an abridged version of this function in \command{coreutils} version 9.5. We now discuss the two transformations we targeted as applications that can be validated via CF-GKAT.

\paragraph{Compilation-decompilation}
We hypothesize that the theory behind CF-GKAT should be usable to validate the output of control flow structuring algorithms in decompilers.
To fully test this hypothesis, we would need to have access to the internal representations used before and after control flow structuring, and convert those to GKAT automata and CF-GKAT expressions, respectively.
Unfortunately, doing this would entail a substantial engineering effort, which would go beyond the scope of this project.
As a more feasible but slightly less rigorous benchmark, we opted to \emph{compile} C code to x86 binary code, and then \emph{decompile} the result using Ghidra.\footnote{\url{https://ghidra-sre.org/}}
This transformation can be implemented without modifying existing codebases, and should still give some insight into decompiler correctness in that it lets us compare the decompiled source to the original.
% We manually inspected negative outcomes to rule out compiler bugs, but did not rule out the (theoretical) possibility of ``two wrongs making a right'', i.e., a bug in the decompiler unwittingly compensating a bug in the compiler, leading to a false positive outcome.

However, we immediately face the challenge of pairing the primitive actions from the decompiled code to their corresponding actions in the source code. 
For instance, a primitive action \lstinline{i += 1} in the source code can be decompiled to \lstinline{i++} in certain contexts.
Detecting \emph{all} such transformations would require a large engineering effort. 
To address this, we make the compiler \emph{blind} to the nature of the primitive actions and primitive tests by replacing primitive actions and primitive tests with calls to new functions \lstinline{void pact(int)} and \lstinline{bool pbool(int)}, respectively. The parameter distinguishes the primitives, and the correspondence in the decompiled code can be inferred from it. Figure~\ref{c:blinded} shows the (abbreviated) \emph{blinded} version of our case study function. Note that this transformation does not alter control flow, but the blinded code can be longer, as the blinder also expands preprocessor macros.
Crucially, blinding depends on indicator variable detection, since indicator tests and assignments need to remain in the blinded code.

In this experiment, we utilize Ghidra as our decompiler of choice, and clang as our compiler.
%FIXME: verify the above sentence 
The C code obtained from compiling and then decompiling the blinded code (Figure~\ref{c:blinded}) is shown in Figure~\ref{c:ghidra}. 
We have manually removed some decompilation artifacts, for example the expression \lstinline{(pbool(n) & 1) != 0} is simplified to \lstinline{pbool(n)} in conditional expressions.
The code produced by Ghidra is markedly different from the source---it has 3 more labels (and 3 additional corresponding \command{goto}s)---yet our implementation is able to validate that this output is equivalent to the original.

\paragraph{Goto-elimination}
In general, \command{goto} statements can be eliminated from C code by introducing additional indicator variables to guide the control flow~\cite{yakdan_NoMoreGotos_2015,DBLP:journals/cacm/BohmJ66,erosa-hendren-1994}.
% TODO: We need an example here.
% CZ: is the reference enough?
This is the idea that underpins a classic \command{goto}-elimination algorithm proposed by Erosa and Hendren~\cite{erosa-hendren-1994}.
% We used our implementation to validate the results of two implementations of this algorithm: \emph{goto-be-gone}, an implementation available on GitHub\footnote{\url{https://github.com/rdbliss/gbg}}, and
Calipso~\cite{casse_ApprochePourReduire_2002}\footnote{\url{https://github.com/BinaryAnalysisPlatform/FrontC}} provides an improved implementation of their algorithm.

We ran Calipso on the blinded code in Figure~\ref{c:blinded}, and manually adjusted the output to change instances where the newly-introduced variable \lstinline{factor_found} is used as a Boolean (as integers and Booleans are indistinguishable in C) into proper comparisons (e.g., \lstinline{if (factor_found == 0)}). Our tool confirms that the code thus obtained is equivalent to the blinded input. Note that indicator detection is crucial: if \lstinline{factor_found} is not detected as an indicator, its assignments and tests will be converted into primitive actions and tests respectively. Thus, the output by Calipso will be fundamentally different from the blinded source, as it contains at least one primitive action or test that is not present in the input.

Overall, we consider our results quite promising: despite the fact that our current prototype does not support C constructs like the \command{switch} statement, we are able to blind 836 of the approximately 1.4K functions in \command{coreutils} for our experiments. A relatively simple program transformation would allow us to support \command{switch} statements when the expression being switched on is a variable. 
However, supporting \command{switch} statements in general still requires notable additions to our theory.
Support for other constructs, e.g., properly supporting \command{do-while} loops and providing robust support for the conditional (ternary) operator would also require extensions to our theory, but it is quite possible to embed special cases in the current theory of CF-GKAT.


\section{Related Work}%
\label{sec:related-work}

% We identify and discuss related work in three distinct areas.
% Kleene algebra, program equivalence, and abstract interpretation.

% \subsection{Kleene Algebra}

Existing work has explored non-local control-flow structures and indicator variables within the framework of KAT, albeit with a number of differences from our work.  

Kozen characterized the semantics for programs with non-local control-flow structures as a family of KAT expressions~\cite{kozen_NonlocalFlowControl_2008}.
This approach yields a decision procedure for program equivalences, by reducing them to KAT equivalences.
In contrast, CF-GKAT takes a more explicit approach by defining the continuation semantics, and the equivalence is computed by converting programs directly into automata.
Our method closed an open question by \citet{kozen_NonlocalFlowControl_2008}, on whether non-local control flow structures can be treated ``directly'', without being converted into KAT expressions.

\citet{grathwohl_KAT_2014} proposed \emph{KAT+B!} an extension of KAT with ``mutable tests'', which can be regarded as indicator variable where there are only two possible indicator values \(I = \{\true, \false\}\).
Concretely, their setter \(b!\) equates to indicator assignment \(x = \true\) and \(\overline{b}!\) to \(x = \false\); similarly, their tester \(b?\) corresponds to primitive indicator tests. % chktex 40
Although this is a special case of indicator variable, KAT+B!\@ can simulate indicator variable over a finite set \(I\) with \(|I|\) mutable tests.
For example, indicator assignments $x := i$ can be simulated by ${b_i!} ; Π_{i' ≠ i}(\overline{b_{i'}}!)$, where each mutable test \(b_i\) records whether the indicator variable \(x\) is assigned to \(i\). 
We opt to treat indicator assignments and tests as primitives, rather than restricting ourselves to (boolean-valued) mutable tests.

Our treatment of indicator variables also draw inspirations from NetKAT~\cite{Anderson_Foster_Guha_Jeannin_Kozen_Schlesinger_Walker_2014}. 
Specifically, NetKAT can be seen as a special case of KAT with indicator variables, the only primitive action is \texttt{dup}.

To reason about variable assignment beyond indicator variables, Schematic KAT~\cite{angus_KleeneAlgebraTests_2001} provides a fine-grained algebraic theory for assignments over uninterpreted functions.
Later, Schematic KAT was also extended to reason about local variables~\cite{aboul-hosn_LocalVariableScoping_2008a}.
Neither work covers the complexity of the equivalence problem for schematic KAT and its extensions.
Kleene algebra can also be extended with nominal techniques~\cite{kozen_CompletenessIncompletenessNominal_2015,kozen_NominalKleeneCoalgebra_2015,gabbay_FreshnessNameRestrictionSets_2011a}, which may help to reason about potentially infinite data domains, although the inclusion of tests to nominal Kleene algebra has not yet been investigated.

Separately, \citet{kozen_CertificationCompilerOptimizations_2000c} have applied KAT to verify compiler correctness. 
Their system directly uses postulated equalities for parts of their verification task. 
In contrast, our framework is based on the trace semantics, a commonly accepted semantics for \command{while}-programs.

Finally, unlike the systems above, our system is based on GKAT, instead of KAT\@. 
This enhances the scalability of our equivalence checking algorithms to accommodate larger programs: whereas equivalence of KAT expressions is PSPACE-complete~\cite{Cohen_Kozen_Smith_1999}, equivalence of CF-GKAT expressions can be verified in polynomial time for a fixed number of tests~\cite{Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}.
Symbolic techniques previously applied to KAT may also provide better ways of mitigating the complexity of tests~\cite{pous_SymbolicAlgorithmsLanguage_2015}.

Our system is the first to integrate both indicator variables and non-local control flow in a unified framework, which enables the verification of complex control-flow transformations that leverage both indicator variables and non-local control flow~\cite{yakdan_NoMoreGotos_2015}.
Our notion of trace equivalence is also coarser than previous systems; CF-GKAT equates programs ending in different indicator values:
\[
    \begin{array}{c}
    x := \true; \comITE{x = \true}{\command{print(1)}}{\command{print(2)}} \\[1mm]
    x := \false; \comITE{x = \false}{\command{print(1)}}{\command{print(2)}}
    \end{array}
\]
The above two programs are equivalent to an outside observer, as both of them will print 1; yet the assignment of \(x\) is different at the end of the program, thus previous systems like KAT+B!~\cite{grathwohl_KAT_2014} will not be able to equate these two programs.
As a trade-off, our equivalence is not a congruence.
For example, equivalence is not preserved under sequencing with \(\comAssert{(x = 1)}\):
\begin{align*}
    (x := 1) & ≡ (x := 0)\\
    (x := 1); \comAssert{(x = 1)} ≡ \comAssert{\true} & ≢ \comAssert{\false} ≡ (x := 0); \comAssert{(x = 1)}.
\end{align*}
Intuitively, \((x := 1) ≡ (x := 0)\) because we disregard the different ending indicator values \(1\) and \(0\). However, this distinction can be observed by sequencing both programs with the assertion \(\comAssert{(x = 1)}\): if the the indicator value is \(1\), then the assertion will not have any observable effect; if the indicator value is \(0\), the assertion will reject all the previous traces.
Thus sequencing an assertion after two equivalent programs will not necessarily preserve the equivalence.



\section{Conclusion And Future Work}%
\label{sec:conclusion}

In this paper, we introduced CF-GKAT (Control Flow GKAT), a system that extends GKAT with non-local control flow and indicator variables to validate control flow transformation programs. 
We formalized two semantics for CF-GKAT\@.
The first is the continuation semantics, where each trace, represented as a guarded word, is augmented with a continuation. The second is the trace semantics, which is obtained by resolving the continuations in the continuation semantics.

We proposed CF-GKAT automata as the operational model for CF-GKAT programs, where the operational semantics is obtained by the Thompson's construction~\cite{thompson_ProgrammingTechniquesRegular_1968,Smolka_Foster_Hsu_Kappé_Kozen_Silva_2020}.
Concretely, Thompson's construction for CF-GKAT turns every CF-GKAT program into a CF-GKAT automaton, while preserving its continuation semantics.
This conversion allows us to design an efficient equivalence checker for CF-GKAT programs, by lowering their Thompson automata into GKAT automata.
Notably, the complexity of this decision procedure scales nearly linearly with respect to the size of the input CF-GKAT programs. 
Thus, our work provides an efficient validation algorithm for various control flow transformations that utilize indicator variables and non-local control flow~\cite{yakdan_NoMoreGotos_2015,erosa-hendren-1994}.

While we successfully addressed one of Kozen's questions~\cite{kozen_NonlocalFlowControl_2008} by presenting an algorithm to directly convert CF-GKAT programs into automata, we have yet to develop a coalgebraic perspective on non-local control flow utilizing Brzozowski derivatives~\cite{brzozowski_DerivativesRegularExpressions_1964}.
Such an approach could streamline several proofs, such as trace preservation of the lowering (\Cref{the:cf-gkat-automaton-lowering-correctness}) and the correctness of the operational semantics (\Cref{the:thompson-correctness}), and lead to a memory-efficient on-the-fly algorithm for trace equivalences between CF-GKAT programs.
A coalgebraic checker could also make use of symbolic techniques~\cite{pous_SymbolicAlgorithmsLanguage_2015} to prevent explicit calculations based on the atoms of a Boolean algebra.

Additional future work could be the inclusion of the \command{continue} command within loops, as well as other types of control flow found in modern programming languages such as \command{do}-\command{while} and \command{switch}.
In terms of the theory's extensibility, it would be beneficial to separate the treatment of indicator variables and non-local control. 
Currently, both components are integrated into the CF-GKAT automata signature as a unified entity. 
While this approach provides a compact definition of operational semantics, it also introduces complexities when incorporating other non-local controls like \command{continue}.  
Specifically, we will need to pass the indicator value in the continuation for \command{continue}, despite none of the non-local control-flow structures changing the indicator variable.

